# Parameters and Variables
In the most **abstract sense**, within the context of **differentiation** and **[[Abstract Mathematical Spaces#Differentiation is the Mechanism of Change|differentiated states]]**, **parameters** and **variables** serve as fundamental components that describe **how** and **what** aspects of a system can **vary**. 
	Their definitions and roles help frame the **process of differentiation**, which is the method of distinguishing distinct possibilities or potential outcomes within a system.
## Parameters (not Independent Variables)
Parameters represent the **constraints** or **defining conditions** that shape how variables behave. 
	They are the **controllers** or **regulators** of a system’s behavior, setting the **conditions** that the variables must follow.

**Parameters** act as **constraints** that shape or control the relationship between the variables, defining the **range of possible values** or the **rules of interaction** within the dimensions.
	Parameters can be thought of as **the rules** that **constrain** how much **freedom** a variable has to take on values within its dimension.
		In more general terms, parameters can be thought of as **defining characteristics** or **properties** that specify the nature of the constraint.
		    They provide the **context** in which the variables interact, giving structure to the relationship.

Parameters are used to **differentiate** by imposing **specific conditions** on how the system can change.
	They act as **boundary markers** that limit and structure the potential variability within a system.

In an equation, parameters can be seen as **aspects that characterize the structure of the relationship**. 
	They define certain fixed properties of the constraint, while the variables can change.

**Parameters** are the **definers** of a differentiated state because they determine **how variables are constrained**. 
	The differentiated state of a system is defined not only by the values of its variables but also by the **configuration of its parameters**, which set the rules for how the variables interact.
##### Parameters Formally
In a formal sense, **parameters can be described as fixed quantities within a constraint (equation) that determine the specific characteristics, scaling, or form of the relationship between the variables**. 
	They shape the structure of the equation and provide the conditions under which the variables satisfy the constraint.
		**Parameters are constants that scale, adjust, or control the relationship between variables** in an equation.
			They act as **defining characteristics** of the constraint, specifying the nature and structure of the relationship.
				**Parameters are essential aspects of the implementation** of an [[Abstract Mathematical Spaces#Equality Constraints Equality The Fundamental Constraint|equation]], influencing how variables interact to satisfy the constraint.
###### Parameters as Scaling Factors and Modifiers
Parameters often appear in equations as **coefficients** or **constants** that **scale** variables, influencing the magnitude or direction of their relationship.
    For example, in the linear equation:y=mx+by=mx+b mm and bb are **parameters**:
        mm is the **slope parameter**, scaling the rate of change of yy with respect to xx.
        bb is the **intercept parameter**, shifting the position of the line along the yy-axis.

These parameters control **how the variables relate to each other**, setting the specific form of the constraint that the variables must satisfy.

**[[AAD Algorithms-Aided Design Parametric Strategies using Grasshopper/AAD/Data/Abstract Mathematical Spaces/Components of Differentiation/Parametrization|Parametrization]]** is the process by which Parameters are injected and arranged, therefore, a system's potential is **structured** or **differentiated**.
	It sets up the relational conditions that allow for specific **instances** of the system to emerge, turning the abstract potential of differentiation into a **well-defined state**.

- - -
## Variables
Variables are **abstracted expressions** of the **potential for variation**. 
	They allow the system to **differentiate** along different axes or dimensions. 
		The act of differentiation assigns variables to specific dimensions, representing the measurable ways in which the system can **vary** or **change** within the space of potential.

**Variables** represent the specific values of the properties (i.e. dimensions) where this identity can manifest its variance.

Variables can be more specifically considered to be **Dependent Variables**.

**Variables** are the **quantitative markers** of a differentiated state.
	They express the system's **configuration** in terms of measurable values, which describe the **state’s position** relative to its potential variance.
### Variables as Differentiated Potentials (i.e. [[Abstract Mathematical Spaces#A Second Differentiation as a Second (Independent) Dimension|Second-Level Differentiation]])
**Variables** represent the specific states ***of*** **aspects of the system that are free to vary** or change. 
	In the context of differentiation, variables capture **how much** a differentiated state can change within the potential defined by the system.

- **Dimensions** provide the abstract **potential** for change or variance (first-level differentiation).
- **Parameters** define the **constraints** or **rules** that structure how a dimension behaves (second-level differentiation).
- **Variables** emerge as **quantified instances** within the system, representing the **specific values** that variables can take, **within the constraints** defined by parameters (third-level differentiation).
### Variables as Degrees of Freedom
They are the **quantitative representations** of how much a system varies along that dimension.

Abstractly, variables are the **degrees of freedom** that express the **potential for variance** along a particular dimension.
	Each variable represents an **axis** or **property** that can assume different values, defining the ways in which the system can change or be measured.
	    **Example**: In a 2D system, $x$ and $y$ are variables representing two degrees of freedom (e.g., space). 
		    Each variable quantifies how far the system has moved or varied along these axes.
### Variables with Infinite Degrees of Freedom
In an **abstract sense**, a **variable** can have **infinite degrees of freedom** when it is **unconstrained**by parameters within a structured relationship, and thus, free to take on **any value** within its dimension.
	In this case, the variable represents **pure potential** for change, with no restrictions or boundaries imposed on it. 
		I.e. A variable with infinite degrees of freedom **represents the system’s maximum potential for variation**.

The variable is not yet bound by any **parameters** or **constraints**.
	The system is in an initial, **undifferentiated state**, meaning that the variable can span the entire **domain** of possible values.
		The system has not yet been **defined** or **refined** by additional structures.
### Variables as [[Abstract Mathematical Spaces#Quantification (of the First Dimension) as the Outcome of Parametrization of the First Dimension|Quantifications]] (i.e. [[Abstract Mathematical Spaces#3. Third-Level Differentiation (Definition of an Instance to a Defined Constraint within the Defined Dimension Quantification Implemented by Value Assignment)|Third-Level Differentiation]])
Variables are **quantifications** of a system’s **state**.
	They don’t inherently represent [[Abstract Mathematical Spaces#1. First-Level Differentiation (Initial Definition of Dimension)|the essence of a differentiated state]] but rather provide **measurements** or **values** that describe the current configuration of that state.
	    **Example**: If a system has the potential to change spatially, then the variable $x$ would be a **quantitative representation** of position along the $x$-axis. 
		    The values of $x$ quantify how much the system has changed within that dimension.

**Variables** represent the **actualized differentiated states within a given dimension** and correspond to what we previously referred to as **third-level differentiation**—the **definition of an instance to a defined constraint within the defined dimension**. 
	At this level of differentiation, we are moving from the **abstract definition** of a dimension and the **introduction of constraints** (via parameters) to the **realization** or **instantiation** of specific **differentiated states**.
		**Variables** are the **quantifiable aspects** of the system that take on specific values **within** a dimension, constrained by the **parameters** and the relational structure previously defined.

**Variables** are the **measured values** or **quantified instances** that describe the system's current state within a given dimension.
	They are the **output** of third-level differentiation, where constraints are applied, and specific instances (or solutions) are realized.
		Variables represent the **outcomes** of differentiation—the quantitative ways in which the system’s potential for variance can be measured. 
			They describe the **specific instances** that emerge from differentiation, representing measurable change within the system.

- - -
## The Relationship Between Variables and Parameters
##### Fundamental (Low-Level) Variables/Parameters
These are parameters that define the very structure or dimensionality of the space or system. 
	They are intrinsic to the definition of the space and can be thought of as representing dimensions themselves.
		**Parameters Represented as Dimensions**: In certain mathematical contexts, parameters are used to define the dimensions of a space or manifold. They are not merely constants but serve as coordinates that span the space.
			Example: In certain mathematical contexts, parameters are used to define the dimensions of a space or manifold. 
				They are not merely constants but serve as coordinates that span the space.
##### Higher-Level Variables/Parameters
These parameters operate within the established dimensions, further constraining relationships between variables or defining specific properties of objects within the space.
	**Parameters as Constants within the Space**: Once the dimensions are established, other parameters can act as constants that define specific properties or constraints within that space.
		**Constraining Relationships**: These parameters affect how variables relate to each other within the established dimensions, shaping the behavior or properties of objects.
### Degrees of Freedom
Each [[Abstract Mathematical Spaces#Dimensions|dimension]] introduces a new **degree of freedom**, and you need one parameter to control or describe each of those degrees.
	The number of **intrinsic dimensions** (the fundamental degrees of freedom of the space) dictates how many **parameters** are required to describe any point within that space. 
		In an $n$-dimensional space, you need $n$ parameters because each dimension allows for an **independent way** in which the points can vary.
	
The **degrees of freedom** in a system correspond to the number of **independent variables** that can be freely assigned values.
	**Constraints** (equations) reduce the number of degrees of freedom because they establish relationships between the variables, limiting the number of variables that can vary independently.
		 **Parameters** help define the specific characteristics of the constraint (e.g., the slope and intercept in a linear equation).
		    **Variables** represent the quantities that can change, and they must satisfy the constraints, which define their allowable relationships.
##### The Number of Degrees of Freedom 
$$\Large \text{Degrees of Freedom}=n−m$$ Where $n$ is the number of variables, and $m$ is the number of independent constraints.
#### Independent Variables, $\LARGE n-m$
**Independent variables** are variables that can be **freely assigned and varied values** without being directly determined by other variables in the system.
	They represent the **degrees of freedom** within the system, meaning they can be varied independently to explore different possible states or configurations.

**Independent variables** can be treated as **parameters** when they are used to control or specify the state of the system. 
	These **independent variable**s are free to vary and define the configuration of the identity.
		When you have **$\LARGE n$ variables and $\LARGE m$ constraints**, the number of **independent variables** (free parameters) is $\LARGE n−m$. 
			These independent variables still represent the **dimensions along which the identity can vary**.
				They serve as **inputs** or **controls** that determine the values of other variables in the system.

 **Independent variables** correspond to the ***free* parameters** that can be varied to specify the state of the identity.
	  These are the **inputs** that determine how the identity manifests along its dimensions.
###### Dimensions and Independent Variables 
The **dimensionality** of a space determines the **minimum number of independent variables** required to fully describe a point or an instance within that space.
	Essentially, each dimension introduces a new **degree of freedom**, and you need one parameter to control or describe each of those degrees.
		 In **higher-dimensional spaces**, more parameters are needed because there are more ways in which the points or states can vary. 
##### Parameters vs. Independent Variables
While **independent variables** are **free to vary**, **parameters remain fixed** for a given instance of the equation.
	They set the **conditions** under which the variables interact, shaping the nature of the constraint.
		Parameters are introduced during Parametrization, whereas Independent Variables arise as outcomes of the Constraint' [[Abstract Mathematical Spaces#Operators The Fundamental Mechanism of Constraint (specifically of the Equation)|structure]] and [[Abstract Mathematical Spaces#Parametrization A Higher-Level Mechanism of Constraint (specifically of the Equation)|characterization]].
			**Parameters** provide the **framework** or **rules** that govern the relationship, while **independent variables** are the inputs that vary within that framework.
#### Dependent Variables, $\LARGE n$
**Dependent variables** are variables whose values are determined by the **independent variables** through the **constraints (relationships)** in the system.
	They are not free to vary independently; rather, their values are **constrained** by the relationships with the independent variables.
		**Dependent variables** are the **actualized values** within those dimensions that result from setting the independent variables. 
			They are constrained by the relationships defined in the system, ensuring that the identity satisfies the given conditions.

**Dependent variables** are determined based on the values of the **independent variables (parameters)** through the constraints that relate them.
	When the system imposes **$\LARGE m$ constraints**, these constraints reduce the number of independent variables, and the remaining variables become **dependent on the independent variables** to satisfy the constraints.
		They **quantify the dimensions** by taking on specific values that satisfy the relationships imposed by the system.
### How Parameters Reduce the Degrees of Freedom
A **[[Abstract Mathematical Spaces#Constraint The Mechanism of Definition|constraint]]** is an [[Abstract Mathematical Spaces#Equations The Fundamental Mechanism of Equality|equation]] that imposes a relationship between variables.
	It defines a condition that the variables must satisfy. 
		The number of **degrees of freedom** (i.e., the number of variables that can vary independently) in a system depends on the number of **variables** and **constraints** (equations).

When you add **constraints** (equations) to a system, you reduce the number of **independent degrees of freedom**.
	Each **constraint** (equation) typically relates some variables to each other, thereby **reducing** the number of variables that can be freely chosen.
#### Why One Equation Constrains Only One Degree of Freedom
The reason lies in the nature of **equations as relationships**:
	**An equation defines a condition** that the variables must satisfy, but it typically involves more than one variable when there are multiple dimensions (properties) in the system.
		When you have more than one variable, the equation does not specify unique values for all variables but instead describes a **relationship** among them, leaving some variables free to vary independently.
$$\LARGE \text{A single Differentiated State in 1D: } \quad p = x$$
			It cannot be $p + y = n$ because it is a single dimension whereby only one aspect is variable (i.e. only one dimension has variance).
				$y$ has no ability to vary and thus cannot ***be*** a variable.
				
Inequalities in this First Dimension defines a set of Differentiated States.
$$\LARGE \text{A set of Differentiated States in 1D: }\quad p \leq x$$
In general, **one equation constrains one degree of freedom**, meaning it reduces the number of independent variables by one.
	If you start with $n$ variables and have one equation (constraint), the number of **degrees of freedom** is reduced to $n−1$.
		The equation provides a relationship that connects the variables, but it leaves some freedom to choose certain variables independently.
			 The remaining variables are then determined by the equation.
##### Case 1: One Equation, One Variable (1 Equation, 1 Variable)
When there is **one variable** and **one equation** (constraint), the equation **fully determines the value of that variable**.
    **Reasoning**: The single equation provides a direct relationship that the variable must satisfy, leaving no freedom for the variable to vary independently. 
	    It must take on the specific value that satisfies the equation.
	**Example**: If the equation is x=5x=5, then xx is constrained to be exactly 5.
		 There is **no freedom left**, and the variable is **completely dependent** on the equation.
##### Case 2: One Equation, Two Variables (1 Equation, 2 Variables)
- When there are **two variables** and **one equation**, the equation **reduces the degrees of freedom by one**, leaving **one independent variable**.
    - **Reasoning**: The equation imposes a relationship between the two variables, but does not fully determine both of them. Instead, it allows for one variable to be chosen freely (independent), while the other variable is constrained by the equation (dependent).
    - **How It Works**:
        - The equation relates the two variables in a way that one variable's value determines the value of the other.
        - **Example**: For the equation x+y=5x+y=5, you can choose any value for xx (independent), and then yy will be determined by y=5−xy=5−x (dependent).
        - In this case, **one variable remains independent**, and the other is dependent on the value of the independent variable through the equation.
##### Case 3: One Equation, Three Variables (1 Equation, 3 Variables)
- When there are **three variables** and **one equation**, the equation reduces the degrees of freedom by one, leaving **two independent variables**.
    - **Reasoning**: The equation imposes a relationship among the three variables but does not fully determine all of them. Instead, it allows for two variables to be chosen freely (independent), while the third variable is constrained by the equation (dependent).
    - **How It Works**:
        - The equation expresses one variable in terms of the other two, meaning you can freely choose values for two variables, and the third variable's value is determined by the equation.
        - **Example**: For the equation x+y+z=10x+y+z=10, you can choose values for xx and yy freely, and then zz is determined by z=10−x−yz=10−x−y.
        - Here, **two variables remain independent**, while the third is dependent on the values of the two independent variables through the equation.
#### Mechanism of Reducing Degrees of Freedom via Parameters
The process of **differentiation** and **constraints (implemented by parametrization)** structures the system, progressively refining it from **infinite potential** to specific, **quantified instances** by applying constraints that limit the ways in which the variables can vary, reducing the degrees of freedom at each step.
##### By [[Abstract Mathematical Spaces#Constraints|Constraining]] a [[AAD Algorithms-Aided Design Parametric Strategies using Grasshopper/AAD/Data/Abstract Mathematical Spaces/Components of Differentiation/Parametrization#Effects of the Configuration of Parameters Relative to Variables|Configuration]] (i.e. Parameters as Definers of Relational Structure/Fixed Relationships)
Parameters define the **relational structure** that variables must adhere to. 
	They describe how **variables interact** with each other or with the system’s underlying framework.
		 The values of parameters serve as **conditions** that shape the system’s behavior, introducing **constraints** that limit the ways in which variables can vary.

Parameters define the **relationship** between variables, such as specifying proportionalities, rates of change, or other structural conditions.
	These relationships reduce the possible values a variable can assume, thus limiting its freedom to vary.
	    **Example**: In the linear equation $y=ax+by$, the parameters $a$ and $b$ fix the **rate of change** (slope) and **position** (intercept) of the variable $y$. 
		    This relationship constrains $y$ to behave in a specific way relative to $x$, reducing the system’s degrees of freedom.
##### By Defining Boundaries (i.e. Parameters as Constraints)
Abstractly, parameters impose **boundaries** or **rules** that govern how the system can differentiate.
	They define the **limits** or **ranges** within which variables can change, serving to **structure** the behavior of the system.
		 **Example**: In a linear system like $y=ax+by$, the parameters $a$ and $b$ control the **slope** and **intercept** of the line, effectively shaping how the variable $y$ changes with respect to $x$. 
			 Here, parameters govern the **relationship** between the variables.
 
Parameters can impose **boundary conditions** or limit the range of possible values a variable can take.
	This confines the variable to a specific **region** or **interval**, eliminating the possibility of infinite variation.
	    **Example**: In the inequality $0\leq x\leq10$, the variable $x$ is constrained to the interval [0,1][0,1] by the parameters defining the lower and upper bounds.
		     This reduces $x$'s degrees of freedom from infinite (without constraints) to a finite range within which it can vary.
##### By Adding Dependencies
When parameters introduce **dependencies** between variables, they reduce the overall **independent degrees of freedom**.
	A system with several variables might initially have a large degree of freedom, but as more parameters are introduced that link variables together (e.g., through constraints or relationships), the number of **independent variables** decreases, reducing the system’s total degrees of freedom.
	    **Example**: In a 3D space, if you constrain the system such that $\LARGE x+y+z=1$, the variables $x$, $y$, and $z$ are no longer fully independent. 
		    One variable (say $z$) can always be determined in terms of $x$ and $y$, reducing the system’s degrees of freedom from 3 to 2.
#### Parametrization and the Reduction of Freedom
**[[AAD Algorithms-Aided Design Parametric Strategies using Grasshopper/AAD/Data/Abstract Mathematical Spaces/Components of Differentiation/Parametrization|Parametrization]]** refers to the process of introducing **parameters** that define the relationships between variables. 
	By parametrizing a system, we effectively **structure** the system’s degrees of freedom, reducing them from infinite or unrestricted possibilities to **specific pathways** or **ranges** within which variables can vary.

**Parametrization** defines how the variables are allowed to vary within a dimension.
The **variables** are **expressions** of how the parameters constrain the dimension's potential.
	They tell us how much the system has varied or where the system currently exists within that potential space (e.g., at a particular point on a curve, surface, or more complex structure).
		In the recursive process of **differentiation**, where each layer of definition adds more specificity to the potential of a dimension, **variables** act as the **tools** or **markers** for realizing that specificity. 
			They carry the **specific values** or **states** that the system takes on as we progressively add more constraints or parametrization to refine the dimensional space.
				As we apply more constraints through parametrization (second-level differentiation), the variables become more **specific** instantiations of the dimension’s potential, ultimately leading to **quantified outcomes** in the form of a solution set.
###### Examples of Parametrization Reducing Degrees of Freedom
- **Line in 2D**: In a parametric equation for a line, such as:
$$x=tx=t, y=2t+1y=2t+1$$
	The parameter $t$ controls the system, and both $x$ and $y$ are dependent on it. 
		This reduces the degrees of freedom from two (one for $x$ and one for $y$) to **one**, as the parameter $t$ dictates the values of both variables.

- **Ellipse in 2D**: In parametric form, an ellipse can be described as:
$$x=a⋅cos⁡(t),y=b⋅sin⁡(t)x=a⋅cos(t),y=b⋅sin(t)$$
	The parameter $t$ reduces the degrees of freedom by **governing** the values of $x$ and $y$ simultaneously. 
		Here, the variables $x$ and $y$ are no longer free to vary independently but are constrained to follow the elliptical path, where $a$ and $b$ define the axes of the ellipse, and $t$ controls the position along the curve.
##### Effect of Parametrization on Freedom
Parametrization **reduces freedom** by:
- **Constraining variables to follow specific paths** (as in the case of parametric curves like lines, circles, or ellipses).
- **Establishing dependencies** between variables, meaning that the value of one variable directly influences or determines the value of another.
- **Restricting** the range of values a variable can take by imposing relationships that must be satisfied (e.g., equations, inequalities, or conditions).
### Produce Differentiated States
**Differentiated states** are the **instances** of a system that arise when variables are assigned specific values within the constraints imposed by parameters. 
	The differentiated state of a system is defined by the **interaction** between variables and parameters.

**Parameters constrain variables**, leading to the emergence of specific **instances** that satisfy the relational structure defined by those parameters. 
	In this sense, differentiation is the process of **imposing constraints** (through parameters) on **potential variance** (expressed by variables) to produce **distinct, differentiated instances**.
#### Variables as the Realized Solution Sets within a Dimension
In the **third-level differentiation**, variables represent the **realized solutions** within a dimension, based on the **constraints** introduced by parameters.
    The variables are now **bound** by the relationships defined at the second level (e.g., $y=2x+3$.
	    Each variable, such as $x$ or $y$, **quantifies** the system’s behavior, taking on specific **values** that satisfy the constraints.

In this framework, **variables** are the **realized instances** of a system’s potential, representing **differentiated states**within a dimension. 
	They are not merely abstract potential for change but rather the **specific values** that a system takes on after undergoing differentiation and constraint through parameters.
	    **Variables describe the differentiated state** within the system after all constraints have been applied.
		    In this sense, the **value assignment** to a variable is the point at which an **abstract potential** becomes a **concrete instance**.
##### The Set of Instances: Solution Sets
The **outcome** of the process of quantification is the **specific values** or **instances**—the **realized solutions** or **differentiated states** that satisfy the constraints. 
	This is the set of **actualized values** or configurations that result from the imposed constraints and parametrization.

The collection of all possible states (instances) derived from configurations that satisfy the constraints imposed by the parameters within the dimensions.
	Solutions represent the specific states of the system where the parameters take on certain values.

Each solution within a **solution set** is a **specific realization** of the system's potential, constrained by the imposed conditions. 
	In this sense, solutions are the **differentiated instances** themselves, but now they are **realized** within the **constraints** defined by the system.
		The **solution set** doesn’t represent abstract possibilities anymore—it represents the **concrete** outcomes or states that the system can take on given the constraints.

In systems with multiple **constraints**, the solution set represents the **intersection** of all the constraints. 
	These intersections correspond to the **differentiated instances** where all the constraints are satisfied simultaneously.

The **solution set** is essentially the **outcome** of **parametrization** and **constraint**.
	The process of constraining a system with equations or inequalities narrows down the possible differentiated states to a specific set of **solutions**that fit within the defined conditions.
		Each **solution** is a **specific instance** or **differentiated state** that has been realized through the **application of constraints**. 
			These instances represent the system’s possible configurations under the given conditions.