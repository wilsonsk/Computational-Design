---
up:
  - "[[Data]]"
related:
  - "[[Abstract Mathematical Objects]]"
  - "[[Abstract Concept]]"
  - "[[Probable Reality]]"
date created: 2024-04-22
---
# Abstract Mathematical Spaces
A map from the abstract notion of environment, to the physical space.

Abstract Mathematical Environments are themselves considered mathematical objects.
	In fact, one of the powerful aspects of mathematics is its ability to treat collections of objects, along with the structures and operations defined on them, as single entities that can be studied and manipulated.
## The Abstract, Non-Physical Environment
**Fundamentally** a **scale** is **defined** by the **Mathematical, Abstract, Non-Physical Environment** that **defines** and **constrains** the Mathematical Abstract Non-Physical **Objects** and their behaviors and interactions that are **analyzed** at that scale.
	It employed because it facilitates clear, objectively causal relationships between these abstract objects.
		Thereby, defining and enabling these Abstract Mathematical Objects and their behaviors (possible [[#State|states]], properties, conditions, parameters) and the interactions (i.e. rules of interactions and relations) defined between them (called "additional structure).

Defines the scales, quantum to macro of the object and their interactions and behaviors.
###### Reduction of Complexity: 
A non-physical abstract environment reduces complexity by isolating mathematical concepts from physical attributes. This allows mathematicians to focus on logical relationships without interference from external factors like measurement errors or material properties​​.
###### Facilitation of Clear, Objective Causality: 
Abstract environments provide a setting where relationships between mathematical objects are governed by pure logic, enabling clear, objective causality between them. This clarity helps mathematicians to deduce properties and explore mathematical truths through proofs and axioms​​.
###### Elimination of Ambiguity (i.e. clear, agreed upon, unambiguous definitions): 
In abstract mathematics, concepts are defined rigorously through axioms and definitions, avoiding the ambiguity that can occur in the physical world​​. This allows mathematicians to draw clear conclusions and develop theories with internal consistency.

- - - 
## A Hierarchy, Structure
The hierarchy from the most fundamental mathematical concepts (universal superset) to fields, spaces, categories, etc., is structured by increasing levels of complexity and structure.
	Each subsequent level derives its elements and properties from the more fundamental levels, creating a layered approach to mathematical concepts.
- - -
## Differentiation: The Mechanics of Change
### The Foundational Notion: Change
#### Change
**Change** is the fundamental process that initiates the potential of differentiation and transition/transformation.
	**Change** is the **force** that drives everything to happen.
		**All processes involve change** in some form, but **change** is a more neutral, foundational concept.

At its core, **change** is the process by which **potential** becomes **actualized** into a specific, defined state. 
	**Change** is the movement from a state of **non-definition** (or a possible state) to a state of **definition** by way of expression, definition and thus differentiation, and it is through this transition that identity and being are established.
		**Differentiation** produces a distinct state, and **definition** describes what that state is, **expression** is how this state **appears** or is **communicated**.

This movement from formlessness to form, from one state to another, and is expressed through the relationships between **definition**, through **constraints** creating an **identity** which itself is composed of dimension(s), these dimensions are lower-level identities defined prior.
	**Expression** through **constraints**, implemented by **parametrization** (the configuring of parameters) which leads to **quantification** creating **instances** of the identity.
#### Differentiation: The Mechanism of Change
**Differentiation** is **how change produces a distinction**, and it **is the smallest degree of change**.
	**Differentiation** is the **moment** that something changes or evolves and becomes distinct from other states or possibilities.

**Differentiation** is the core process of **change**—it creates the distinction between one state and another, by which a state of being emerges from a field of possibilities. 
	When **change** occurs, something transitions from an undefined state to a defined one. 
		If this change leads to a state that is now **recognizable** or **distinct** from other possibilities, we call this **differentiation**. 

Differentiation is the **moment** when something becomes **distinct** or **separate** from something else after the process of change has acted on it.
	Differentiation happens **because of change**—it's the **outcome** that allows us to see that something has become distinct.
		Therefore, differentiation is the type of change that leads to **distinction**.

Without differentiation, no change can be perceived because all would remain in an undifferentiated, static potential.
	Differentiation is what transforms potential into specific, distinguishable states.
		It is the process by which change produces **distinctions**, **separating** one state, entity, or concept from others.
			**Differentiation** is a **specific type of change**—it’s the type of change that produces **distinction** and **identity**, making a state of being **recognizable** and **unique**.
				While change can refer to any transformation, **differentiation** is the particular kind of change where something becomes **distinct** from something else.

The initial change is that from the undifferentiated, absolute to the first duality or relational existence of two interdependent states. 
	The states being most simply "**is**" and "**is not**", that is "**equality**" and "**inequality**".
		Which through the notion of value expressed as quantity which is expresses as numbers, can be described as $\LARGE 1$ and $\LARGE 0$.
### The Process of Differentiation
[[#1. First-Level Differentiation (Initial Definition of a Dimension) An Initial Discernment (Distinguish), $ LARGE [0 space 1]$|First-Level Differentiation]] ***via*** [[#Definition The Mechanism of Discernment (of the First-Level Differentiation)|Definition]] ***via*** [[#Constraint The Mechanism of Definition|Constraint]] **via** [[#Equality (and thus Inequality) as the Fundamental Constraint|Equality]]/[[#The Implicit Role of Inequality (What It Is Not)|Inequality]] **via** [[#Equations The Fundamental Mechanism of Equality|Equation]] ***Produces*** [[#Identity The Assertion of Boundaries of a Definition|Identity]] *->* [[#The First Dimension A Higher-Level First-Level Identity|Dimension]] ([[#The First Dimension A Higher-Level First-Level Identity|a higher level identity]])

[[#2. Second-Level Differentiation (i.e. Second-Level Definition/Constraints) A Second-Level Definition (i.e. Second-Level Conditions) of a First-Level Definition (i.e. Identity/Dimension)|Second-Level Differentiation]] (of a Dimension) ***via*** [[#Second-Level Constraints Bound a First-Level Dimension|Second-Level Constraint]] ***via*** [[#Equation Represents the Constraint|Equation]] via [[#Operators The Fundamental Mechanism of Constraint (specifically of the Equation)|Operators]] (structure) && [[#Parametrization A Higher-Level Mechanism of Constraint (specifically of the Equation)|Parametrization]] (characterization) 

[[#3. Third-Level Differentiation (i.e. Third-Level Definition/Constraints) A Third-Level Definition (i.e. Third-Level Conditions) of a Second-Level Definition|Third-Level Differentiation]] ***via*** [[#Instantiation (i.e. Instance) of the Identity Parameter Value Assignment|Instantiation]] (value assignment of parameters) ***Produces*** (Specific) [[#An Instance Within the First Dimension (i.e. Reducing the Degrees of Freedom)|Instance of Variance within the Dimension]] ***produces*** [[#The Instance A Solution Set (i.e. A Quantification of the Variables/Instance)|Solution Set]]
##### The Logic of Quantity: The Outcome of Differentiation
##### Repeat Process for a Second, Third, Fourth, ..., Dimension
##### Repeat the Process for a Composite Composed of Dimensions
Identity composed of Identities.
	Instances composed of Instances.

- - -
## Recursion: The Differentiation of a Differentiation, the Definition of a Definition
At the **fundamental level**, a dimension (or a differentiated state) is defined through **differentiation**—meaning that it is recognized as a **distinct potential** for variation or change. 
	This is the **first-level differentiation**, where the dimension is **defined** as being distinct from other dimensions (e.g., space vs. time, x-axis vs. y-axis).
		The **initial definition** of a dimension sets up the **general nature** of the dimension, describing its **potential**for variance.

The process of **defining** and **differentiating** is recursive, meaning that **each layer** of definition can be **refined** by further constraints and specifications. 
	You can continue adding more layers of differentiation and parametrization to make the system more and more specific.
		This layered process is what leads to more **specific instances** or **well-defined states** within the broader framework.
			Each layer of definition (or differentiation) brings the system closer to a **concrete state** from its original abstract potential.
## A Map From the First Change to Patterns of Change: Layers of Definition and Differentiation
### 1. First-Level Differentiation (Initial Definition of a Dimension): An Initial Discernment (Distinguish), $\LARGE [0 \space 1]$
The first Initial Change (the first relational existence).
	When we speak of the **first differentiation** as the **distinction** between "this (1)" and "that (0)," we are essentially describing the **emergence of contrast** or the creation of a **boundary**.
		 This act of differentiation introduces the concept of **difference** and thereby establishes the **relationship** between **two states**.
			  This differentiation creates a **binary distinction**, marking the **interdependent existence** of "0" and "1." 
				 Both rely on each other to define what they are; "0" is understood as **not-1**, and "1" as **not-0**.

At this **base (i.e. first) level**, you have an **abstract definition** or **differentiation**: the establishment of a dimension or an aspect as a potential for variation.
	This is where a dimension or state is **distinguished** from others, forming the **foundation** of a framework. 
###### The Relational and Interdependent Nature of the First Differentiation 
The identity of this first dimension is inherently **relational** and **interdependent**.
	"0" and "1" do not have meaning in isolation; they **define** each other through their difference.
		The **interdependence** implies that this dimension encapsulates the fundamental quality of **existence through differentiation**.
			By differentiating "this" from "that," it defines the basic framework of identity.
#### Definition: The Mechanism of Discernment (of the First-Level Differentiation)
The recognition of a **state of differentiation**, even at an abstract level, would require some **formal mechanism** to **discern** or **distinguish** that state from what it is **not**. 
	This is true whether we are defining a dimension, an object, or a state of existence.
		This act of **differentiation**—**distinguishing** "this" from "not that"—is fundamental to how a dimension or state is defined, even before parametrization.
			This **recognition** or **discernment** requires a formal way of saying: **"This state is defined as A, and not B."**
#### The Absolute Degrees of Freedom
Before differentiation and thus existence of a state, no bounds yet existed around "this" or "that".
	The Degree to which that non-differentiated state could vary was beyond infinite, it was absolute.
		Once the act of Discernment takes place, it reduces the Degrees of Freedom.
##### The Logic of Definition: The Principle of Identity and the Principle of Non-Contradication
A thing is **itself** and **not something else**.

To **recognize differentiated states**: we formally **assert** that something is **equal to itself** (this is **A**) and by implication, **not equal to something else** (this is **not B**). 
	By saying **"this is A"**, we are, at a formal level, **equating** the state to a **specific identity**.
		This assertion involves **equality** because we are identifying the state as **itself**.
		    Implicit in this act of **equality** is the differentiation from **what it is not**.
			     By equating the state to **A**, we are implicitly asserting that it is **not B**, **not C**, and so on.
##### Identity: The Assertion of Boundaries of a Definition
At the most fundamental level, the **definition** of any abstract differentiated state involves the assertion of **identity**, which is formally implemented through **equality**.
	To recognize/discern something, you need to assert that it is **equal to itself** and, at the same time, **not equal** to other things.
		**This assertion is called a Definition**.
			An Identity arises from this **act of distinguishing** one state from another.

An **Identity** can also be called a **Type**.
	It refers to the **essence** or **core property** of an entity or state that distinguishes it from all others.
		A **type** is a more **general definition** resulting from a **lower level** differentiation.
			It is the **result** of the process or "act" where something is defined, that is asserted to be equated to some specific property or properties (i.e. conditions).
				When we Define an **Identity/Type**, we are drawing a boundary around a set of general attributes that define what it means to be part of that type.
					Identity in this form is still **abstract**—for example, the concept of **blackness** or **whiteness**.
						That is, an Identity is not defined by a specific "**Value**".
							The Identity is an unrealized abstraction with potential for variation.   
##### Constraint: The Mechanism of Definition
**Definition** is what **shapes** identity.
	**Definition** is the **imposition of conditions, limits or boundaries (i.e. establishing of properties and characteristics)** around **what it is** and **subsequently define what it is not** (that which is outside the boundaries), thus creating the **conditions for differentiation** (i.e. **creating the constraints**).
		Identity only emerges within a boundary—a constraint that excludes all other possibilities.
			**The Definition binds an Identity to specific "properties" and excludes it from being those not within those constrained bounds.**

At the most fundamental level, the **definition** of a differentiation (or any abstract differentiated state) involves the assertion of **identity**, which is formally implemented through **constraint**.
	**Definition** is the **imposition of conditions, limits or boundaries (i.e. establishing of properties and characteristics)** around **what it is** and **subsequently define what it is not** (that which is outside the boundaries), thus creating the **conditions for differentiation** (i.e. **creating the constraints**).
###### [[Constraints|Constraints]]
**Constraint** is a **condition** or **rule** that bounds, limits or defines what is (**possible**). 
	A constraint **narrows** the possibilities of how something can exist or behave by setting **boundaries**. 
		By specifying the conditions under which **limiting** the set of possibilities, constraints drive the movement from potential to actualized states.
			 In doing so, they bring about **change** by determining which states of being are allowed to emerge.
				 Constraints **shape the solution space (instance of an identity)** by narrowing down the set of possible combinations of variable values that meet all the imposed conditions.

**Constraints (equations) are expressions that impose conditions on the variables (via operators and parameters), defining specific relationships that the variables must satisfy to be considered valid solutions (instances)**.
	They use **parameters to characterize the form and nature** of these relationships, while the variables are subject to the rules defined by the constraints.
		More specifically, a **constraint** is an **equation** that imposes a relationship between variables. 
			It defines a condition that the variables must satisfy. 
##### Equality: [[Constraints#Equality|The Fundamental Constraint ]]
Constraints are Imposed (i.e. implemented/assigned/defined) by Equalities/Inequalities.

**Constraint** is enacted (i.e. "**assigned**") through **equalities and inequalities**, which assigns/imposes the relational conditions/constraints/boundaries to the corresponding differentiated state/form/expression.
	To define is to assert that **this = these properties**.
		 This is what creates the **constraint**.
			- Example: Defining a chair involves saying that a "chair" equals "a seat, with legs, a backrest, designed for sitting."

**Equality** is fundamental because it provides the most direct way to **differentiate** a state.
	By imposing equality, you **collapse** the potential variability into a **specific state**, thereby creating a **differentiated instance** of the dimension.

At the most fundamental level, the **definition** of a differentiation (or any abstract differentiated state) involves the assertion of **identity** via constraint, which itself is formally implemented through **equality**.
	**Equality** allows us to say that the dimension is **itself**—that it represents a specific type of potential variance. 
		This recognition is the first step in defining what the dimension is.
			By asserting that **this differentiation is itself**, we are also implicitly saying that **it is not** other dimensions. 
				This process involves **negation** or **exclusion** as part of the **recognition** of the differentiated state.
###### Equality
Equality at this low level can be understood as a **formal mechanism** that constrains or binds an **identity** to its definition.
	When we say something is **equal to itself**, we are affirming its **existence** as a **distinct state**.
		 This process of affirmation naturally leads to the recognition of what it is **not**, through a process of **exclusion** or **negation**.
			Therefore, even in an abstract, pre-parametrized sense, **equality** functions as a means of **formal recognition**. 
				It allows for the definition of something as **this** (through **identity**) and, by extension, the discernment of what it is **not**.
					**Equality** (and **inequality**) serves as a mechanism for **fixing** or **restricting** the potential states of differentiation.
 
 To discern **"this" from "not that"** at the lowest level, we rely on the formal process of **equality** (or identity).
	  We say that **A = A** (this dimension is itself), and this formal assertion allows us to recognize that **A ≠ B** (it is not the other potential states).
		  In this way, **equality** serves as the formal **implementation of discernment**: by equating something to itself, we establish its identity and differentiate it from everything else.
  
  Equating Provides the **Basis of Identity**.
	Defining a differentiated state, effectively equates it with a constraint (i.e. set of properties or conditions). and thus establishes the differentiated state’s **identity**. 
		This equating is a fundamental part of **definition** because it is the act that ties a differentiated state to its specific constraints.

Equality as the **Fundamental Constraint** **assigns/fixes** a parameter within its space, reducing the dimension's variability to a single point. 
	It serves as the foundation upon which more complex constraints can build.
##### The Implicit Role of Inequality (What It Is Not)
**Inequality** is implied in this process as well of Definition as Instantiation.
	By defining **A** as **equal to A**, we are also saying that **A is not B**, **A is not C**, and so on. 
		The process of **differentiation** naturally implies the recognition of **inequality**—the recognition that what is **"A"** is **not** the other potential states or dimensions.
			This **formal mechanism** of differentiation, which begins with asserting **identity** through **equality**, includes the implicit negation of other possible states or dimensions.
				 This is how the differentiated state is **recognized** as distinct from what it is not.
##### Equations: The Fundamental Mechanism of Equality
An equation as the fundamental mechanism of equality, **formalizes the condition** that two expressions must satisfy the same value.
	The **equation as a whole** serves as the **implementation of the equality constraint**, integrating these elements to define the relationships between variables and parameters in a precise way.
###### Equations
An **equation** is a **mathematical statement that asserts the equality of two expressions**. 
	It is the **formal representation** of the constraint, indicating that the left-hand side and right-hand side must be equal under the given conditions.
		In this sense, the **equation acts as the mechanism** that **implements the constraint of equality**:
		    - It specifies **what needs to be equal** (the two sides of the equation).
			- It provides a **framework for relating variables, parameters, and constants** through **[[#Operators The Fundamental Relational Structure of Constraint|operators]]**.

 The equation establishes a **relational structure** in which **equality is enforced** through operations (defined by operators) and relationships between terms.
###### Equation Represents the Constraint
**Therefore, the equation is the representation of a constraint.**
	Where **constraint** $\LARGE \equiv$ **equation**.

A **constraint** is an equation that imposes a relationship between variables.
	It defines a condition that the variables must satisfy. 
		The number of **degrees of freedom** (i.e., the number of variables that can vary independently) in a system depends on the number of **variables** and **constraints** (equations).
##### The First-Level Equation Constrains One Degrees of Freedom
This First-Level Definition constrains some dimension from the what it is not.
	These bounds reduce the Degrees of Freedom.
		Without constraints, there would be no limits, and without limits, nothing can be defined or distinguished. 
			With no discernment there is only [[#The Absolute Degrees of Freedom|Absolute Degrees of Freedom]].
				The First-Level Differentiation constrains the Absolute into Infinite via the imposition of boundaries. 

Remember, **Definition** is what **shapes** identity by imposing constraints, boundaries, limitations on what an Identity is equated to be. 
	Identity only emerges within a boundary—a constraint that excludes all other possibilities.
		**The Definition binds an Identity to specific "properties" and excludes it from being those not within those constrained bounds.**

The First-Level Equation constraints (i.e. defines) a single relationship among the identity, where this one equation fully determines that variable (it becomes dependent).
	The single equation provides a direct relationship that the variable must satisfy, leaving no freedom for the variable to vary independently. 
		It must take on the specific value that satisfies the equation.
			Each constraint **reduces the degrees of freedom** in the system [[Parameters and Variables#Mechanism of Reducing Degrees of Freedom via Parameters|by one]], because it imposes a new rule that the variables must satisfy.
#### The First-Level Definition (of the First Differentiation)
When defining a **discernment** or any abstract differentiated state, the process is not just about **recognizing** its potential for variance but also about **formally stating** what it **is** and what it **is not** (i.e. defining).
	The process of **equality**—asserting **A = A**—is a formal way to instantiate that **discernment**. 
		This act of equating something to itself allows it to be recognized as a distinct state, separate from everything else.
##### The First-Level Identity
This initial differentiation creates an **identity**. 
	The core property of this initial/fundamental differentiated state is embodiment of the **essence of duality**—the simultaneous presence of "this" and "that," "0" and "1."
		**I.e. The core property is "this" and not "that".**
			That is, its core property can be simply represented by a "$1$".
				Where the single property is the definition of the identity itself.
###### **At this First-Level, the First-Level Identity is $\LARGE \equiv$ Inherent Property of Itself**
**I.e The First-Level Identity $\LARGE \equiv$ The First-Level Dimension $\LARGE \equiv$ The Inherent Property**
This identity is abstract and fundamental because it serves as the **groundwork** for all further differentiation. 
	It is the "first step" that allows for more complex structures, properties, and identities to emerge.

Remember that despite being defined as a simple binary property, this identity itself, is still potential.
	That potential being the potential for variance within itself.
##### The First Dimension: A Higher-Level First-Level Identity
An **identity** can be thought of as a **distinct, defined entity** that has certain **characteristics or properties**. 
	It represents a **specific aspect of variation** or **potential for definition** within a larger context.
		An Identity is **shaped by the kind of potential it uniquely represents**.
			We call this abstract potential of variance, a [[Axes and Dimensions|Dimension]].
				**Dimensions** represent the **potential degrees of freedom** or **properties** that an identity can have. 
					When an identity is used to define or describe a higher-level identity, it effectively becomes one of the **dimensions or properties** that contribute to the definition of that higher-level identity.
 
 Here, the **dimension** represents the fundamental ability to **distinguish** or **change** between states - it is an intrinsic "difference".
	 A **dimension** represents an **aspect of potential variance or change** within a system. 
		It provides a **framework or context** in which something can vary or be defined.
			In this sense, a dimension is a **high-level identity** because it encompasses a broad **category of potential variation**. 
				It defines a **space or scope** in which more specific, lower-level identities can be actualized.

Therefore, this dimension is a **differentiated state** on its own because it encapsulates the primary **potential for change**—the existence of a "difference" between two relational states.
	In abstract terms, this first dimension embodies the **concept of distinction**, which is a foundational property that enables all further differentiation and definition.
		Before a differentiation is used in the definition of a more complex state, its identity is defined **by its own inherent property**.
			 It is not yet bound to specific constraints or configurations; it simply **"exists"** as a potentiality, an abstract foundation upon which more complex forms can be built.

In this framework, the act of differentiation—splitting into "this" and "that"—introduces the **first dimension**. 
	 This is an isolation of a specific potential for change.
		 The dimension formed by the distinction between "0" and "1" becomes a **unique entity** that defines a kind of **existence**: the existence of **difference** or **contrast**.
			 This dimension is an aspect that has the potential for variability, the **space of potential variance** defined by the contrast between "0" and "1." 
				The **identity** here is not tied to specific characteristics (like "length" or "time") but rather to the **very nature of differentiation** itself. 
###### Dimension
A **dimension** is initially defined as a **space of potential variability** or **differentiation**. 
	It represents a fundamental way in which a system or entity can **vary** or **change**.
		At its most basic level, this **definition** is abstract—it establishes the **potential** for differentiation but does not yet fix the instances within the dimension into specific states.
			 The dimension exists as a **framework** for possible variance, a "field" where future constraints will create specific instances.

 This relational aspect is crucial because it shows that the **dimension** itself is not just an isolated entity but a **differentiated state** defined by its **contrast**.
	It is the initial "differentiated state" that gives rise to the possibility of all subsequent structures, definitions, and transformations.
		By defining a dimension, you are establishing a **baseline framework**—a unique **field of variance**. 
			For example, the dimension "time" provides a foundation for expressing temporal changes, making "time" an identity unto itself.
				The **difference** of this single property from others (such as "length" vs. "time") comes from its **distinct role** in expressing change. 
					Each dimension's identity is characterized by the type of variance or potential it encapsulates.
##### The First-Level Dimension as Infinite Degrees of Freedom
From Absolute Degrees of Freedom to Infinite Degrees of Freedom.
	Because a Dimension represents potential variance, then until a Dimension is Quantified, the potential/unrealized is represented by Infinite Degrees of Freedom of variance.
#### Implicit First-Level Instantiation
**The First-Level Identity is simultaneously an implicit First-Level Instance of itself.**

When we **differentiate** a single dimension from others, we are already engaging in a form of **First-Level [[#Parametrization The Mechanism of Constraint|Parametrization]]** which leads to First-Level **quantification** (i.e. First-Level Instantiation). 
	This is because, even at an abstract level, we are **assigning a role** or **identity** to that dimension, distinguishing it from what it is not.
		In a sense, we are setting a **BOUNDARY** (i.e. a **constraint** or **parameter**) that says, "This dimension is not like the others."
			 This introduces a kind of **quantification** in the sense that we are **assigning** a property (or potential for variation) to this dimension **in relation to** the other dimensions.
###### Remember the Recursive Nature of Differentiation
This is because despite not being formally instantiated through the means of **Quantification** (more on that later), this **First-Level Identity** exists in a Relational Structure.
	**That is, the First-Level Identity as a First-Level Dimension, exists within an even more abstract "dimension" of these "dimensions", within which this First-Level Identity is an actual variation relative to the variation that represents what it is not.** 
		The Quantification of this First-Level Dimension is the Inherent Property itself that exists relative to what is not that Inherent Property.
##### Implicit First-Level Quantification
At the lowest level, the **value** or **meaning** of a dimension does not necessarily exist **within** the dimension itself but rather **between** dimensions.
	This means that the **identity** of a dimension arises in the context of how it **differs** from other dimensions.
		This quantification occurs in the sense that the dimension is **discerned** or **recognized** as a **distinct entity** among other possible dimensions. 
			The **value** of a dimension doesn’t only come from within the dimension itself, but more importantly, from the **relationships** or **distinctions** between dimensions.
				In this sense, **value** (or **quantification**) arises from the **distinctions** or **relations** between dimensions, **not yet** from properties **internal** to the dimensions.

Even if the dimension is abstract and not yet assigned a specific **numerical value**, its **identity** as distinct from other dimensions creates an implicit **quantification**. 
	This happens because, through **differentiation**, we are already setting a **parameter** that this dimension is **distinct** from others.
		 In other words, we are defining a **role** for it within a larger system of potential variations.

This reflects the idea that **value** in a system of dimensions is **relational**—a dimension gains its identity by being **not the other dimensions**. 
	This inter-dimensional distinction is where **quantification** begins, even before specific values are assigned within a single dimension.
### 2. Second-Level Differentiation (i.e. Second-Level Definition/Constraints): A Second-Level Definition (i.e. Second-Level Conditions) of a First-Level Definition (i.e. Identity/Dimension)
The Definition of (i.e. applied to) a Constrained First-Level Identity or Dimension (where the Identity is the Dimension in this First-Level of Abstraction) implemented by Parametrization.
	I.e. Defining a Relational Structure between the Properties (i.e. Dimensions) of the an Identity. 
		In this sense, **constraints (structured by operators and implemented by parametrization)** is a **Second-Level Constraint** because it **constrains** the potential variability of the dimension by assigning specific **rules** or **values** that shape how the dimension operates.
			I.e. Constraints limit the possible states by **defining conditions** that the variables must satisfy.

The **constraints are implemented through their configuration relative to the variables in the equations or functions**, this process is called Parametrization. 
	Where the **relationships between [[Parameters and Variables#Parameters|parameters]] and [[Parameters and Variables#Variables|variables]]** are set up, typically in the form of **equations** or **operators** that govern how variables can vary within the system. 
		At this stage, the constraints are **deterministic**—they describe how variables behave under fixed, well-defined relationships.
			- [[Constraints#Fundamental Constraint|Fundamental Constraint]]
			- [[Constraints#Low-Level Constraints|Low-Level Constraints]]
			- [[Constraints#Higher-Level Constraints|Higher-Level Constraints]]
##### Constraints Bound a Dimension 
**Constraints** add a **second layer of definition**, introducing boundaries that specify **how** the dimension behaves or what values it can take on.
	In this sense, constraints **defines the range** or **conditions** under which the already-differentiated state operates.
		 It’s a **more specific definition** within the larger, more general framework.
#### Relational Structure: The Second-Level Differentiation
##### Dimension as the Latent Framework for the Relational Structure
The very act of differentiation creates distinctions, and these distinctions imply possible states of variance within that dimension and thus simultaneously relate to another state(s).
	The moment you differentiate between "this" and "that," you introduce a way to relate these states within a context or framework. 
		Dimensions emerge from differentiation as the potential context or framework and then serve as the potential for further variation or change.
			The **dimension** is the **potential** for variation, providing the **conceptual framework**.

Before any constraints are applied, the **dimension** exists as an **abstract potential**—a context that supports **all the possible ways** in which a state can vary.
	This potential is general and not yet specific; it's an open framework that indicates a way in which states could potentially vary.
		
A **dimension** provides the **context** or **axis (in spatial terms)** along which differentiation or variation can occur. 
	It is the **conceptual framework** that allows the differences between states to be mapped or understood.

This differentiation gives rise to a **relational structure** where the **newly differentiated states** are **related** in terms of their differences.
	Once states are **differentiated**, they exist in **relation** to each other. 
		**Differentiation** creates the **conditions** for **relations** like **before and after**, **greater and lesser**, **equal and unequal**, or **cause and effect**. 
			These relationships are the basis for **logic** because logic formalizes how these states interact and connect based on their differentiated properties.
				These relationships create **structures** that can be ordered, compared, and understood in terms of their differences or similarities.
#### Operators: The Fundamental Mechanism of Constraint (specifically of the Equation)
Operators define the Relational Structure of the Constraint/Equation.

Operators can be understood as **mechanisms that define the nature of interactions** between terms (variables, parameters, and constants) within an equation.
	 They **shape how constraints are expressed**, dictating the kind of relationship that must hold true for the variables and parameters (e.g., linear, quadratic, exponential).
		Their primary role is to **specify how different components combine or relate** to each other.
			By specifying operations, operators **shape how the constraint affects the variables** and parameters.
				**Operators enable the expression of various types of relationships**.

**Operators are mechanisms of constraint,** but not constraints themselves. 
	They shape how the relationship or constraint is applied, rather than being the constraint.
		They **determine the form** of the relationship in the constraint. 
#### Parametrization: A Higher-Level Mechanism of Constraint (specifically of the Equation)
Parametrization defines the Characterization of the Relational Structure of the Constraint/Equation.

**Parameterization** works within the framework **established by the operators**:
	Once the **form of the relationship (i.e. the equation)** is defined (e.g., linear, quadratic), parameterization **adjusts the characteristics** of that relationship (e.g., slope mm, intercept bb in a linear equation).
		**Parameterization is dependent on the structure** established by operators and serves to **fine-tune or characterize**the relationships within that structure.
		    Parameters **scale, shift, or otherwise adjust** the variables, but they rely on the operators to define how these adjustments affect the relationship.

**Parameterization is dependent on operators**, as it uses the operations defined by the operators to implement specific constraints:
	In $y=mx+b$, the parameter mm scales the variable $x$, but this scaling is only meaningful because the **operator $x$** (multiplication) defines how mm interacts with $x$.
		Similarly, $b$ shifts the result, but the **operator $+$** (addition) specifies how this shift occurs.
			**Operators do not depend on specific parameters**, but they provide the **framework** in which parameters operate.

In a way, **operators are structural components** of constraints, defining the **nature of the interaction**, while **parameters adjust the properties** of that interaction.

At a **higher level**, you **introduce and configure** **specific constraints** or **definitions** through parametrization, which further refines how the initial framework behaves.
	This is where we **refine** the framework by introducing **specific constraints** or values. 
		Constraints limit the possible states by **defining conditions** that the variables must satisfy.
			These Differentiations are the requirements the subsequent instances must satisfy.

**Parametrization** is the act of creating a **relational configuration, arrangement or framework** (i.e. **rules**) that defines how **[[Parameters and Variables#Variables|variables]]** depend on **[[Parameters and Variables#Parameters|parameters]]**. 
	 It is about configuring the **[[Parameters and Variables#The Relationship Between Variables and Parameters|relational structure]]** that governs how the variables behave within the system, with the **parameters** serving as the elements that shape or control this behavior.
		This framework sets up the **conditions** and **structure** of the system, without necessarily assigning specific values to the parameters immediately.
			The system’s behavior is structured but **not yet fixed** in terms of specific values.
				 In mathematical terms, **parametrization** involves expressing one or more **variables** in terms of one or more **parameters**. 
###### Variables
The **dimensions** correspond to the **variables** of the system.
	Each **variable** represents a dimension in the space where the system operates.
		**Variables** are the **actualized values** within a given dimension. 
			They represent the **specific states** or values that the dimension takes under the influence of the system’s constraints.

**Variables** are the **specific manifestations** of the dimension's potential. 
	They are the **quantitative (i.e. actualized) representations** of how much a system varies along that dimension.
		The **quantitative/actualized state** is simply the **realized form** of the dimension in that specific instance.
			In this way, each specific value that a variable assumes within a dimension is an **instantiation** or **realization** of one of the possible states of that dimension. 
				The dimension provides the **context for variation**, and the variable’s value selects a specific **actual state** from that potential.
 
 In this sense, variables take on values that are **measures** of the **state** within a particular dimension.
	  In other words, variables provide the **actual values** that describe a system's state **within** a dimension, while the dimension itself represents the **potential** for those values to exist. 
		  So, a variable is the **[[#Instantiation (i.e. Instance) of the Identity|instantiation]]** of the dimension’s potential at a given moment or in a given context.
			   *For example:* In the context of spatial dimensions like $x$, $y$, and $z$, the dimension $x$ represents the **potential** for a point to exist at any location along the x-axis. 
				   The **variable** $x$ then takes on specific **numerical values** that describe a particular point or state along that axis.
						If $x=5$, this means the point exists 5 units along the x-axis—this is the **quantitative realization** of the dimension’s potential.
###### Parameters
In the context of parametrization, parameters are generally **constants** or **controlling quantities** that govern how variables behave or change. 
	They are typically **independent** from the system’s main variables, that is, **independent** quantities, that define the system's structure, rules for how variables behave.
		Parameters govern the possible configurations of the system without yet assigning specific values.

**The parameters** provide the **rules or constraints** that **bind the variables**, ensuring that they take on values consistent with the defined system.
	**Variables**, are **dependent** quantities whose values are determined by the relationships defined by the parameters.
		Variables describe the system’s state within the dimensional space.
			 A variable is an **instantiation** or **realization** of the abstract **potential** provided by the dimension. 
				 The variable’s value at any given moment or under specific constraints (e.g., through parametrization) represents a **specific state** within that dimensional framework.
###### Example: [[Points as Position Vectors#A Vector is a Linear Combination of Basis Vectors of the Entire Vector Space|Basis Unit Vectors]]
$$\LARGE \vec{r} = ax + by$$
Here a position vector is higher-level differentiated state (i.e. an oriented point), a defined identity equated to two properties (i.e. dimensions).
	The **variables** $\LARGE x,y$ are potential differentiated states of their corresponding dimensions.
		The potential values (states) of the variables are constrained by the **parameters** $\LARGE a,b$.
#### Second-Level Constraints Bound a First-Level Dimension 
By constraining a First-Level Dimension, the **constraints (implemented by parametrization)** themselves represent a **higher-level definition** because they **bound** the potential variability of the dimension by assigning specific **rules** or **values** that shape how the dimension operates.
	I.e. Constraints limit the possible states by **defining conditions** that the variables must satisfy.

**Constraints** add a **second layer of definition**, introducing boundaries that specify **how** the dimension behaves or what values it can take on.
	In this sense, constraints **defines the range** or **conditions** under which the already-differentiated state operates.
		 It’s a **more specific definition** within the larger, more general framework.

When a **Second-Level Constraint** is imposed on a differentiated state, it defines the **parameters**, or boundaries. 
	**Constraints** then **formalize** the latent dimensions by setting boundaries, defining how variation can occur.
		By doing so, the constraint **transforms** the abstract potential into a **specific, aspect** of variation, essentially giving the dimension its **formalized structure**.
### 3. Third-Level Differentiation (i.e. Third-Level Definition/Constraints): A Third-Level Definition (i.e. Third-Level Conditions) of a Second-Level Definition
Defining an Instance.

**Parametrization** and **constraint** are **processes** that lead up to instantiation, but the **instantiation itself** happens when those constraints result in specific, **quantified outcomes**.
	A system can be defined or constrained abstractly through parametrization, but it does not become **instantiated** until the **values** are assigned to the parameters, creating a specific instance of the system.
		The process of **instantiation** is the process of finding or determining the **solution set**, where the abstract identity (defined by constraints and parameters) is made **concrete** by **actual values**.
		    In this way, the **solution set embodies the instance** because it captures the specific configuration of the system that satisfies all conditions.

Once the **structure** is defined through parametrization, you can assign specific values to the parameters, which then produces specific **outcomes** or **instances** of the system.
	The **solution set** is essentially the **outcome** of **parametrization** and **constraint**.
		The process of constraining a system with equations or inequalities narrows down the possible differentiated states to a specific set of **solutions**that fit within the defined conditions.
			Each **solution** is a **specific instance** or **differentiated state** that has been realized through the **application of constraints**. 
				These instances represent the system’s possible configurations under the given conditions.
#### Instantiation (i.e. Instance) of the Identity: Parameter Value Assignment
The Definition of an Instance of a Second-Level Constraint of the First-Level Identity ([[#**At this First-Level, the First-Level Identity is $ LARGE equiv$ Inherent Property of Itself**|in this First-Level case]], it is within the First-Level Defined Dimension).
	I.e. Instantiation via **Quantification (of the Dimension(s)) Implemented by Value Assignment (to the Parameters).**
		So, the **instantiation of an identity** is the process by which a **defined set of characteristics or properties** (parameters and constraints) is brought into reality through the assignment of specific values (variables) that satisfy those definitions. 
			The **identity** becomes **actualized** as a **differentiated state** when all the conditions that define it are met.
				The **parameters** dictate the nature of the relationships (constraints) thus the ways the properties of an identity can vary.
					The **variables** represent the properties (i.e. dimensions) where this identity can manifest its variance.
					    The **solution set** provides the **instantiated values**, making the identity an actualized state within the framework.
##### **Instantiation through Value Assignment** **collapses** the **Potential Variability** (i.e. Dimension) into a **Specific State**.
I.e. **Instantiation** is the process of making the abstract definition **real or concrete** by assigning **specific values to the parameters and variables** within the defined framework.
	When you assign specific values to the parameters, you are **actualizing the potential** and thereby **quantifying the identity**.
		In the case of a system of equations, it involves finding the **solution set**, which actualizes the identity in a concrete form by satisfying all the constraints that define it.

**Instantiation** occurs as the **outcome** of the assigning values to the Parameters of the Constraints. 
	Which then quantifies the variables into values, and thus instantiates a state (i.e. instance) the dimension(s).
		In other words, it happens when a specific, quantifiable state or instance is **realized** after constraints have been applied and parameters have been set.
			The act of **applying constraints** and **parametrization** defines the **conditions** under which the system will instantiate particular states that satisfy those conditions.
				 However, the **actual instantiation** occurs when specific values (i.e., **quantified outcomes**) are assigned to the variables, thus producing a **concrete instance** of the system.
					 During **parametrization** and **constraint**, we are still operating in the realm of **potentiality**—we are setting up the conditions under which **specific states** can arise, but we have not yet realized those states.
						The system becomes **instantiated** once the **specific values** (solutions or outcomes) that satisfy those constraints are **realized**.
							 At this point, the system has moved from an abstract potential to a **concrete state**—this is the **moment of instantiation**.
#### The Instance: A Solution Set (i.e. A Set of Quantifications/Instances of the First-Level Dimension)
$$\LARGE [0 \space 1] \to [0 \space 1 \space 01 \space 11 \space 001 \space 011 \space 111 \dots]$$
The assigned values to the parameters, in combination with the constraints, lead to the **quantification of the instance**, meaning that all variables in the system are now specified.
 
The **solution set** represents the specific, concrete **instance** of the identity—meaning, the actual values of the variables that satisfy all the constraints defined by the system.
	When we refer to an **instance**, we're talking about a **particular realization or occurrence** of an identity within the defined framework of constraints.
	    The **solution set** is precisely that: it is the collection of **specific values for the variables** (i.e. specific values of variance of the dimensions) that satisfy all the relationships (constraints) in the system.
		     This collection represents the **actualized form** of the identity as defined by the given parameters

The solution set represents the **actualized, concrete realization** of the identity, where the defined relationships, parameters, and constraints come together in a specific way to form a particular occurrence (instance) of the identity.
	That is, the quantification of the dimensions of the identity.
##### The Solution Set is the Actualized Values
The **solution set** **is** the **quantification of the dimensions** within the constraints of the system.
	It represents the **actualized values** of the variables that satisfy all the conditions imposed by the **parameters and relationships** within the system.
		The **solution set** consists of the **specific values** of the variables that meet all the constraints (equations). 
			These constraints are shaped by the **parameters** and how they relate to the variables.

In other words, the solution set is the **"realization"** or **"actualization"** of the potential ways that the variables can exist within the framework established by the system. 
	It represents the **values that the dimensions take on** when all constraints are simultaneously satisfied.
		**Value assignment** to the parameters happens when you want to **instantiate** a specific instance of the system within the already-defined framework. 
			This assignment gives specific, concrete outcomes based on the relational structure.
				The **constraints** (equations) act as **boundaries** or **rules** that limit the possible values that the variables can take, thus **defining a region** (or set of points) where all conditions hold true.
					**Parameters** influence these constraints by shaping the relationships between the variables (e.g., coefficients in a linear equation).
##### The Solution Set as the Actualization of Dimensions
The **solution set** is the **set of all points (values)** where the **quantified relationships** (parameters and constraints) align in such a way that the variables satisfy all the equations.
	Think of the solution set as the **manifestation of the abstract potential** of the dimensions. 
		The dimensions represent the possibilities, while the solution set represents the **specific realizations** that are consistent with the given constraints.
###### The Set of Instances: Solution Sets 
The **outcome** of the process of quantification is the **specific values** or **instances**—the **realized solutions** or **differentiated states** that satisfy the constraints. 
	This is the set of **actualized values** or configurations that result from the imposed constraints and parametrization.

Each solution within a **solution set** is a **specific realization** of the system's potential, constrained by the imposed conditions. 
	In this sense, solutions are the **differentiated instances** themselves, but now they are **realized** within the **constraints** defined by the system.
		The collection of all possible states (instances) derived from configurations that satisfy the constraints imposed by the parameters within the dimensions.
			The **solution set** doesn’t represent abstract possibilities anymore—it represents the **concrete** outcomes or states that the system can take on given the constraints.
				Solutions represent the specific states of the system where the parameters take on certain values.

In systems with multiple **constraints**, the solution set represents the **intersection** of all the constraints. 
	These intersections correspond to the **differentiated instances** where all the constraints are satisfied simultaneously.
#### Repeating: A "Second" First-Level Differentiation as a Second (Independent) Dimension
This Second Differentiated State is not in combination with the First Differentiated State (yet...).
	The same process occurs for this Second Dimension as in the First.
		Where this Second Dimension produces a Second Identity or Type.
			Then the Dimension is Constrained via Parametrization, which produces the Instances  of this Second Dimension.
				Each Instance is a Quantification (i.e. Value Assignment) of this Second Dimension.
### 4. Recursion: Fourth-Level Differentiation (Definition of a Higher-Level Differentiation/Definition/Constraint/Instance)
**Lower-Level Identities** and thus **Lower-Level Dimensions** can serve as the basic properties or aspects that define a **high-level differentiated state** (i.e. more complex systems).
	They represent the potential for variance (or change) within that state.
		Dimensions represent the **potential for change** itself, rather than the specific ways that change is constrained (which is the role of parameters).
			This differentiation creates a basic framework where **one form of variance** (binary change) exists.
				In this state, "0" and "1" represent a single **axis of variation**—a dimension that can toggle between two states.

When multiple dimensions are combined into a new identity, they represent the **internal structure** of this new state. 
	This identity may have more complex behaviors, as it is now constrained by the relationships between its constituent dimensions.
		The **new identity** can be thought of as the **product** of differentiation, where dimensions are no longer independent but rather **interdependent** and **related** through constraints and parameters that govern the overall system’s behavior.

At this level, we are no longer working with individual dimensions in isolation. 
	Instead, we define a **higher-level identity** that **encompasses** multiple dimensions.
		These dimensions are now treated as **properties** or **attributes** of this new identity, where each dimension contributes to the **overall structure** or **behavior** of the system.
			The **identity** itself is the new differentiated state that emerges from the **interplay** between these dimensions.

- - -
## An Application of the Model: Language Theory
### Differentiation as an Alphabet (i.e. set)
- - -




#### The Evolution of the Constraints
##### Dimensionality Determines the Complexity of the Potential Constraints
The **dimensionality** of the space dictates the **complexity** of the potential constraints. 
	In a **one-dimensional space**, constraints are straightforward since they affect variance along a single line.
		In **higher-dimensional spaces**, constraints can describe interactions across multiple dimensions.
			As the **number of dimensions** increases, the nature of the constraints becomes more intricate, allowing for the definition of more complex differentiated states. 
##### How Constraints Evolve with More Parameters
The **dimensionality** of a space determines the **minimum number of parameters** required to fully describe a point or an instance within that space.
	Essentially, each dimension introduces a new **degree of freedom**, and you need one parameter to control or describe each of those degrees.
		 In **higher-dimensional spaces**, more parameters are needed because there are more ways in which the points or states can vary. 
 
With a **single parameter**, the constraint types are basic, typically involving equalities or inequalities.
	With **two parameters** within the same dimension, operations like **addition** or **subtraction** become possible (e.g., defining linear relationships).
		As you introduce more **parameters** and **dimensions** into the space, constraints evolve to include more complex forms of interaction, such as:
			In **multi-dimensional spaces**, constraints become more sophisticated as they can involve interactions between **dimensions** (e.g., $x,y,z$ in 3D space). 
				The **number of parameters** (coordinates) in the space allows for complex constraints like equations of planes ($ax+by+cz=d$), curves ($y=x^2$), and surfaces.
##### Higher-Level Constraints
When dealing with **multiple parameters** within a single dimension or across **multiple dimensions**, you can impose more complex constraints using operations like **addition**, **subtraction**, **multiplication**, and **division**. 
	These operations allow you to express relationships between different parameters.
    
These **higher-level constraints** depend on having **multiple parameters** available to interact within the space.
	In other words, the types of operations you can use to constrain a space grow as the number of parameters increases.
##### The Composite (Higher-Level) Identity: The Definition of a Type/Identity Equated to Multiple Dimensions (i.e. Properties)
An **instance** of 2D space is a **specific point** defined by the **combination** of values from both dimensions. 
	These instances are the **higher-level states** that result from combining the two dimensions. 
		They possess **more than one property** because each point in 2D space inherently includes both an "x" and a "y" value.
			Therefore, the **instances of 2D space** reflect the **interdependent relationship** between the two dimensions.
				 A point in 2D space is **differentiated** not just by its x-value or y-value alone, but by the **specific combination** of both.
##### The Composite (Higher-Level) Instance: The Constrained Instance Within Two (combined) Dimensions: 
The Implementation of the Definition via Constraints (Parametrization)
Implemented through the Increasingly Complex Constraints.
$$\LARGE p + x= y$$
	It ***can be*** $p + x = y$ because it is a multiple dimension whereby.
		$y$ has the ability to vary and thus can ***be*** a variable.

- - -
### Sequence is a Relational Structure
In a mathematical or physical sense, a sequence **utilizes** dimensions (e.g., the "time" dimension for a sequence of events) to **express relationships** between different states in terms of their ordering.

**Sequence** is the **ordered arrangement** of differentiated states based on their **relative differences** (i.e. relational structure) established by the constraints that define them. 
	The constraints that **define** and **differentiate** states also impose an **abstract sequence** on those states.
		As soon as something is differentiated (i.e., distinguished from another state), it enters into a **relationship** with other differentiated states. 
			When multiple states are differentiated, they become **relational** not only in terms of their distinctions but also in terms of their **order**. 
				This order is what we call **sequence**.
					In a sequence, the relationship between states is no longer just about whether one is inside or outside a boundary, but **where** one state exists relative to another.
		
This relationship can be temporal, spatial, or based on any other definable constraint, and it naturally leads to a sense of **before** and **after**, **greater** and **lesser**, **closer** and **farther**, etc.
	This sequence exists purely as a result of the **relative relationships** between differentiated states, such as order in time, space, or other dimensions.

It is the **relational order** that arises from differentiation and the imposition of constraints, independent of any specific numerical values or quantification.
	However, once values are assigned, **quantification** refines this sequence, allowing for precise **measurement** and **comparison** within the ordered structure.
## Logic is the Outcome of the Relational Structure
**Logic** is the **formalization** of the relationships between differentiated states, and it arises from the structure imposed by **differentiation** as a result of **change**. 
	Logic organizes and governs the way we reason about the connections between distinct states and how they interact within the rules of differentiation.
### Logic Emerges from Defined Relationships
**Logic** arises naturally from the system of **definitions** and **constraints** that govern how differentiated states relate to each other. Once constraints are imposed on states, logic formalizes the **rules** for how these states **interact** and **relate**.
- For example, in logic:
    - If we define **A** and **B** as distinct states, we can establish logical rules like "If A, then B" (causal relationship).
    - If A is defined by certain constraints, we can logically infer things about A’s relationship to other states (e.g., A cannot both be true and false at the same time, which is the principle of **non-contradiction**).
### Equality and Inequality: Core Logical Relationships
**Equality** and **inequality** are foundational logical relationships that arise from definition and constraints. 
	When we say "this state equals these conditions," we are creating the constraint that defines the state.
		 Simultaneously, by defining what the state **is**, we are also implicitly defining what it **is not**.

Logic defines the principles by which states relate to one another (i.e. This leads to logical outcomes):
- **Identity**: A state is **equal** to itself and its defining constraints (A = A).
- **Negation**: A state is **not** another state (A ≠ B).
- **Comparison**: One state can be greater than, less than, or equal to another state based on their constraints (A > B, A < B, A = B).

**Logical operations** (such as **and**, **or**, **not**) derive from the constraints imposed by definitions. 
	The definitions of the states involved determine how they can logically interact:
	    - **AND** means both states (A and B) must satisfy their constraints simultaneously.
	    - **OR** means either state A or state B (or both) must satisfy their respective constraints.
	    - **NOT** means the state is **negated**—it does not satisfy its constraints.
## Logic of Causality: Derived from the Sequence of Differentiated States
When constraints are imposed on states in a **temporal or causal** context, logic governs the sequence of **cause and effect**. 
	For example, if A causes B, the logic of **causality** establishes that **A precedes B**.

This causal logic is derived from the fact that the constraints on A lead to the existence or behavior of B.
#### Sequence and Causality
**Sequence** is the foundation for **causality** because causality depends on a clear understanding of **what happens first** and **what happens next**. 
	This ordering (sequence) is what allows us to say that event **A** causes event **B**.
		 If events were unordered or simultaneous without any notion of before and after, causality would lose its meaning.
###### Causality
The principle that one event causes another—naturally arises from the concept of **sequence**. 
	Without sequence, there could be no notion of **before** and **after**, and thus no concept of one event **causing** another. 
		**Causality** inherently requires that events be ordered in time or space, so that one can lead to or affect the other.

- - -
## The Derivation of Quantity
### Logic (of the Relational Structure) is the Basis of Quantity
At its core, **differentiation** is the act of creating distinctness—of saying that **this** is different from **that**. 
	It is the smallest level or most basic form of **change**, and in this process, an entity moves from a state of undifferentiated potential to a state of being distinguishable.
		Differentiation creates the **contrast** between **this** and **not this**, or between **state A** and **state B**.
			As soon as differentiation occurs, we have **multiple states** that can be compared in terms of how they differ from each other.
				The idea that one differentiated state can be "more" or "less" than another (in any magnitude) and that difference can be measured or compared, is what gives rise to **quantification**.

**Differentiation** creates the need for measurement by making things distinct and thereby comparable.
	**Definition** provides the characteristics along which this differentiation can be quantified (such as size, duration, weight, etc.).
		**Constraint** imposes the limits that make quantification possible by defining the **range** or **scale** of possibilities.
			**Equating** is the mechanism by which we compare differentiated states, allowing us to assign numerical values to express the **magnitude** of their differences or similarities.

Without the **logical structure** of relationships and sequence, there would be no framework within which to measure or assign values to states. In other words, **quantification** relies on the **logical relationships** established by sequence to give meaning to the values assigned to states.
### Definition is the Framework for Quantification (i.e. Value Assignment)
To assign a **value**, we need a way to **define** **what is being measured**. 

**Definition** provides the **structure** or **constraints** that can be assigned a value.
	**Definition** is the process by which we specify/impose/assert/bind the constraints/boundaries/properties of a differentiated state. 
		At this level, definition involves **equating boundaries (i.e. properties and characteristics)** that make one state distinct from another.

By defining what something is, you’re also defining the constraints (i.e. axes or aspects) in which you can compare or measure it. 
	**Definition** creates the constraints (i.e. **dimensions** or **parameters**) along which values can be assigned. 
		For example, defining the concept of "length" or "duration" gives us a **dimension** in which differentiation can be **quantified** by assigning values.

Without **definition**, values could not exist because we would have no formal structure for assigning magnitudes to the distinctions produced by differentiation.
### Dimension Derives the Framework for Constraints
###### Dimensions
A dimension is an abstract axis or framework that emerges from the process of differentiation and constraint, providing a context along which a parameters of a differentiated state can be varied.
	I.e. a **dimension** is a conceptual space that arises when a particular aspect of a differentiated state is **constrained** to vary within certain bounds.
		 It gives form to **how** and **in what manner** we can observe, compare, or quantify different states. 
			 Each dimension represents a potential or a scope of differentiation (i.e. in spatial terms: "direction of variation").

A **dimension** provides the **context** or **axis (in spatial terms)** along which differentiation, measurement, or variation can occur. 
	It is the **conceptual framework** that allows the differences between states to be mapped or understood.

	A **dimension** is essentially an **axis** or **direction** along which **quantification** can occur.
		**Dimensions** represent the **scope** or **range** within which parameters can be measured.
			 For example, if a constraint limits an object to a specific length, that length becomes a **dimension** in the form of "distance," along which values can be assigned (e.g., 1 meter, 2 meters).
    
Each **dimension** corresponds to a **parameter** controlled by the constraints. These dimensions allow us to measure and compare different states based on specific properties.
### Constraints Derive Parameters
*Remember*, that **when constraints are imposed on a state (i.e. equated to a differentiated state by definition)**, they **specify the defining aspects** of the entity or state (i.e. that which must be true for that state to exist as it is).
	That is, constraints they **restrict** a state or entity to specific **properties** or **characteristics**.
		And these defining aspects (that are specified by the constraints) are called the **parameters.**

I.e. A **constraint defines the specific aspects (i.e. the parameters)** of differentiated state.
	*And* constraints also **define the bounds of possible variations of that parameter (i.e. specified aspect)**.
		**Parameters** are therefore, **the specified aspects that have a range of variation**, both of which are constrained by the definition of a given differentiated state. 
###### [[Axes and Dimensions#Parameters as Controllers of Axes|Parameters]]
A **parameter is a specific constraint** (property or characteristic) that can be **varied** within the bounds set by the constraints.
	A **parameter** can be thought of as a **controller** that specifies a particular feature or characteristic of a state, allowing it to vary within the imposed limits.
		**Parameters** arise because **constraints limit** what a state can be, and these limits give rise to measurable or definable aspects along which we can assess the state.
### Constraints Derive the Scope of Variation (of the Parameters)
Parameters represent the **aspect** of the entity that can be controlled or measured, and they can vary along a defined **dimension**.
	But these "dimensions" are latent until realized through the process of [[#Quantification|quantification]].
		A parameter is essentially a **dimension of variation** that can take on different values, subject to the constraints. 

Once constraints define parameters, these parameters naturally create **dimensions**.
	When a **constraint** is imposed on a differentiated state, it **limits** or **defines** the possible values that a specific property (parameter) of that state can take. This limitation inherently **creates a context** for understanding that parameter.




### **Actualized values** are the **specific expressions** of the state within the scope of variation, representing a **realized subset** (analogous to the **range**).
### Sequence and Quantification
**Quantification** is inherently **relational** because it assigns **values** based on the **differences** between states. 
	These differences are derived from the **relational structures** established by differentiation.

Thus, **quantification** is made possible by the existence of **sequence**.
	Without sequence, we would not have a way to measure how much one state differs from another, because the idea of **difference** itself requires an understanding of **order**.

Once we establish **sequence**, we can begin to explore the **logic of quantity**. 
	The **logic of quantity** emerges from the relationships established in a sequence because sequence gives us a framework for **comparison** and **measurement**.
		**Quantification** allows us to assign **values** to the constraints that define (i.e. are equated to) differentiated states, but these values only have meaning in the context of their **relationship** to other values in the sequence.

The sequence of values enables the comparison of values.
	And the **logic of quantity** is based on the **ordered relationships** between values. 
		It allows us to understand how values **compare** to one another.
			What is being compared are the differences between the magnitudes of these values.
				These differences represent the relationships between the values and ultimately between the differentiated states.
					A formal system (later defined as a numerical system) enables the expression of these relationships (i.e. comparisons/differences) between values, in the form of **operations**.
						And are also used to manipulate the relationships.
#### Quantification
**Quantification** is the process of **assigning values**.
	**Quantification** is the process that formalizes abstract distinctions/differentiated states produced by differentiation, into formal values, (i.e. measurable "quantities") through the assignment of a **encoded/numerical value** to a **constraint** (which is defined and equated to a differentiated state).

**Quantification** allows us to formalize **how different** one state is from another. 
	It converts the abstract notion of "difference" into something that can be expressed as values.
#### Values
**Values** are **assignments of relational distinction** that arise directly from the process of **differentiation**.
	They represent the degree, magnitude, or "amount" of difference between one state and another. 
		In other words, values are **the formal representation of how much one state differs from another** or how far one state is from a reference point. 
			**Values** are the **quantitative form** of distinctions that emerge from differentiation.
###### Values are Fundamentally Relational
They do not exist in isolation but only in relation to **other states** or a **reference**.
	The represent states of differentiation that are themselves relational, i.e. defined by what they are and what they are not.
		Values exist as means to compare.
			A value gains its meaning from its **relationship** to other values and to the constraints that define the system.
				 A single value is not isolated; it is **defined by its role** within the system's structure, and it exists as part of a **relationship** between different variables or dimensions.

A **Value** is the **specific, measurable representation** of an **actualized identity** of the **state** after it has been differentiated from other potential states.
	These **values** are **context-dependent representations** of the underlying identities. 
		The identities of states exist even without the values, but the values give these identities a **specific, measurable form** in this system.
			A **value** is the specific identity that a state of being takes on after it has been constrained and differentiated.
### Equating as the Basis of Quantification
Previously we discussed equating a constraint with a differentiated state.
	The purpose here is to **define** what the state **is** by ensuring it satisfies the **constraint**. 
		We are saying, "this state equals these conditions."

But in terms of Quantification, the process of quantification involves equating a constraint with a value.
	This is about **quantifying** how much or to what degree the differentiated state fits/satisfies/corresponds to the conditions of the constraint. 
		The **value** reflects the relationship between the state and the constraint in terms of **measurement**.
##### Equating Gives Values Meaning Through Comparison
**Equating** is the process that allows us to assign a **specific value** to a state by comparing it to a **reference** or **standard**.
	Values are derived by **equating** the differentiated state with a **standard** (such as a unit of measurement, a baseline value, or another entity).
		 For instance, when we say the length of an object is 5 meters, we are equating the object’s length with the **reference length** of 1 meter multiplied by 5.
			In the most abstract sense, a value is the result of saying "this state equals this amount" in comparison to some reference.
				Without **equating**, we couldn’t assign precise values because there would be no way to determine how the differentiated state relates to other states or reference points.
##### Equating Facilitates Measurement, i.e. Establishment of Relationships Between States
**Equating** is the process of **comparison**—whether something is equal to or different from something else. 
	This is critical because **measurement is fundamentally a comparison** between two things:
		1. **Quantification** involves comparing a differentiated state to a **reference** (like a ruler, clock, or unit of measure). 
		2. Equating is what allows us to establish **relationships** between states, such as whether one state is **greater than**, **equal to**, or **less than** another.
- For example, equating the length of an object to a unit of measurement (e.g., "this line is 5 units long") is a direct expression of **quantification**.
### Expressions are Quantified Representations (i.e. Measurable/assignable Values)
**Relational values are the formal expressions that can be assigned to the specified constraints that define (i.e. are equated to) a differentiated state.**

Expressions can be understood as **representations** of a state, form, or entity that has undergone **differentiation**.
	Once a state or entity is **differentiated** and **defined**, its **expression** becomes a way to make this state **perceivable** or **observable** in some form.
		When you introduce the idea of **values** into this system, the **expression** of a state becomes its **quantified representation**—a measurable or assignable output of that differentiated state.

In the context of **quantification**, an **expression** can be understood as the **formal output** or **form** of a differentiated state, but **represented in terms of values**.
	These values assign **quantitative meaning** to the properties of the expressed state.
		Thus, expressions are not just abstract forms; they are **anchored** in reality through the **assignment of values**. 
			These values allow the expression to be **communicated**, **understood**, and **measured**.

- - -
## The Logic of Quantity: The Foundation for Mathematics (From Differentiation to Mathematical Structure)
### The Logic of Quantity *is* the Logic of Quantitative Relationships, *is* Mathematics
The **Logic of Quantity** emerges from the **Quantitative Relationships**.
	**Quantitative Relationships** being the way the values representing specific differentiated states (i.e. values assigned to the defined constraints of a state of differentiation) **relate to each other, and these relationships are expressed**.
		
**Logic of Quantity** *is* the **the Logic of Quantitative Relationships (i.e. how quantities interact** and **relate to each other**).

**The Logic of Quantity** is a system that governs how **differentiated states**—which have been defined and constrained—relate to each other.
	It is a systems that facilitates the understanding and formal expression of the **relationships** between **quantities**, which arise from the process of **differentiation** and **change**.
		These relationships are **expressed quantitatively**, meaning they are represented in terms of **magnitude**, **comparison**, and **order** (e.g., greater than, equal to, etc.), and are manipulated using **mathematical operations**.
### The Logic of Quantitative Relationships *is* Mathematics
**The Logic of Quantity** as the framework through which mathematical relationships are derived from **differentiation** and **change**.
	Math being an abstract system for expressing quantitative relationships logically.

Mathematics, in its most abstract sense, is the **formal system** we use to understand, express/describe, quantitative relationships (i.e. differences and interactions between quantities) and (and thus model reality). 
	**Mathematics** becomes a way of describing the **relationships** between differentiated states in a logical, structured way.
		 By understanding how these states are **quantified** and how their **values** interact under certain constraints, we can reason about complex systems and changes in a precise, logical manner.
		 
Quantification being values assigned to the defined constraints of a state of differentiation. 
	At the core of this system lies **quantity**, which is derived from the process of **differentiation**—the act of creating distinctions between states or entities. 
		These distinctions, when formalized into sequences and relationships, form the basis of numbers and, ultimately, the framework for **mathematical reasoning**.

The Logic of Quantity provides the **language, and system of logic** to express the **logic of differentiation, change, and sequence** in a precise and structured way, that we call Mathematics. 
	To lay the foundation for this, we must first explore the underlying principles of **quantity**, **causality**, and **sequence**.
### Relational Nature of Differentiation: Foundation of Sequence (and thus the Logic of Quantity)
At the core of any structured system is **differentiation**, the process by which one state or entity is distinguished from another.
	The moment something is **differentiated**, we are establishing its identity by creating a **boundary** that distinguishes **what it is** from **what it is not**. 
		This act of differentiation is inherently **relational**, because the meaning of the differentiated state depends on its relationship to the other states it has been separated from.

Differentiation is not just about recognizing a state or entity—it is about creating a **boundary** that defines the **limits** or **constraints** of that state. 
	A boundary tells us not only what is inside (what the state **is**) but also what is outside (what the state **is not**).
		 Without boundaries, nothing could be distinguished because all would remain in a state of **undifferentiated potential**.

In this way, **boundaries** are not just constraints/limits—they are the fundamental relational structure that allows **differentiation** to take place. 
	**By defining a boundary, you are relating the differentiated state to everything that lies outside of it.**


##### The Logic of Quantity
Is the system that formalizes the sequence between differentiated states, and by which we understand, identify, express and manipulate **quantities** in relation to each other. 
	This logic enables us to perform operations like **addition**, **subtraction**, and **comparison**, based on the positions of states in a sequence.

### Causality and Differentiation: The Logic of Change
Quantity is just a logical system.
	A logical system that is constrained by rules and these rules define the system.

At the most fundamental level, **causality** is the structure that governs **change**. 
	It defines how one state transitions into another, creating the **before** and **after** relationships that give rise to our understanding of **time** and **sequence**.
		 This causal framework is the foundation upon which the **logic of quantity** is built.
##### Causality and Sequence
**Causality** creates the order of **differentiation**, which means it is responsible for the **sequential relationships between distinct states**. 
	When one event causes another, it introduces a **temporal ordering**, leading to the possibility of comparing and measuring the differences between these states.

**Change**, as experienced in the real world, is always framed by **causal relationships**: one thing leads to another.
	 Without causality, there would be no clear **sequence**, and without sequence, the very notion of **quantity** and **measurement** would be meaningless.

Thus, **mathematics** begins with the recognition of these **causal sequences**, and **numbers** arise as the [[#Expressions are Quantified Representations (i.e. Measurable/assignable Values)|formal way of expressing/representing]] the **order** and **magnitude** of the changes observed.
## Numbers
###### Why Numbers are so Fundamental to Understanding Reality 
The reason **numbers** are so central to humanity’s understanding of reality is that **reality itself is structured in terms of space (i.e. sequence with a spatial component), and logic (i.e. sequence, and causality)**. 
	Everything we observe and experience involves relationships between objects, events, and quantities. Numbers allow us to:
		- **Describe** these relationships precisely (e.g., the position of an object, the distance between two points, or the amount of energy in a system),
		- **Measure** change and structure (e.g., the passage of time, the arrangement of objects in space),
		- **Organize** our thoughts and understanding of the world through logical sequences (e.g., chains of cause and effect, scientific models, mathematical proofs).

Numbers are inherent in our pursuit of understanding because they provide a **formal system** for representing the patterns and structures we observe in reality.
	**Space**, for example, is defined by positions (which we represent with numbers), and **time** is understood through sequences of events (which are also modeled numerically).
###### Numbers as Representing Order -> Sequence -> Position/Location -> Space
The physical world we inhabit is fundamentally a **spatial structure**—it’s made up of objects with positions and locations relative to each other.
	These positions are described in terms of **coordinates** (numbers) that place each object within the framework of space.

The notion of Quantity derives the hierarchy of Order -> Sequence -> Position/Location -> Space.
	Therefore, Numbers through their inherent expression as a code of symbols (i.e. symbols mapping to meaning), can be employed to represent this fundamental notion of Order -> Sequence -> Position/Location -> Space.
		Where Space is sequence with a spatial component.

This is why Numbers are inherent in humanity's endeavor to understand reality. 
	Because our reality is understood through its inherent "space" (i.e. position/location/sequence).
###### Numbers as Representing Time (i.e. Change: "Before" and "After) 
Because Numbers represent order and sequence, the notion of "before" and "after" can be derived.
	**Time** is also a type of space, but for **events**. 
		Numbers allow us to describe the **sequence of events**—the order in which things happen and how they are causally related.
			 This connection between sequence and time forms the basis for our understanding of **causality**.
###### Numbers Through Representing Quantity, Facilitate Logic
Our logic used to understand our reality space is dependent on sequence.
	Humans define Logic as a sequence of events that we call causality.

**Causality** is a sequence of events where one event leads to another. 
	This chain of cause and effect can be modeled using numbers or sequences (e.g., event A happens before event B, or event A causes event B).

**Logic** follows **sequenced steps**—premises lead to conclusions, just as numbers in a sequence follow one another in a structured order. 
	The **order** of logical steps mirrors the order of numbers in a sequence. 
		This order is necessary for logic to function.

This is why they are inherent in humanity's endeavor to understand reality. 
	Because our reality, as space, is understood through its logic.

Numbers are not just abstract; they are the foundation for describing the **relational structure** of reality, both spatially (in terms of where things are) and temporally (in terms of when things happen).

In the broadest context, **numbers** represent **the structure of reality** itself because they allow us to describe the constraints that are equated to/define a differentiated state:
- **Position** in space (coordinates),
- **Order** in time (sequence of events),
- **Relations** between quantities (through operations like addition, subtraction, multiplication),
- **Change** and **transformation** (through functions and mappings between sets).

They are the **symbolic language** that allows us to describe and engage with the world in a structured, logical way. 
	In the context of **space**, **order**, and **sequence**, numbers serve as the tools that encode the relationships and positions that define reality.

Constraints are the building blocks for defining sets, and they are formulated using the fundamental concepts of **logic**.
	Constraints specify the conditions under which elements are included in a set or satisfy a definition.
		Constraints often involve equations (statements of equality) that elements must satisfy.
			In logic, predicates and conditions involve equality to express precise relationships.

## The Universal Superset as the Most Fundamental Mathematical Object
This is the most abstract and comprehensive set, **containing all possible** underlying, structured, and higher-level sets. 
	Think of it as the "universe" of **all** mathematical objects and structures.
		This Universal Superset does not have any constraints applied upon it.
			Therefore a "superset" can be seen as absolute despite technically being a "set".
### Elements (i.e. the Possible Values) of the Universal Superset
#### The Underlying Set (i.e. Base Set)
The most comprehensive set, containing all possible mathematical objects and structures.
	The base set within the universal superset, containing all possible raw abstract mathematical objects.
#### Elements of the Underlying Set
Contains the "**all possible**" raw Abstract Mathematical Objects without any additional structure or defined operations.
	All conceivable mathematical entities, both structured and unstructured.

A **Universal Superset** is the concept of **"all possible values"**. 
	This superset can be thought of as representing **every conceivable value** that a variable or set of variables could take.
		In mathematical terms, you might imagine this as the set of **all real numbers** $\mathbb{R}$, which encompasses every possible number, whether positive, negative, rational, irrational, or infinite. 
			**Conceptually**, it represents a space of **total freedom** where no values are excluded or constrained. 
				Every possible value is included in this universal set.
##### 1. Numerical Sets
###### Natural Numbers ($\mathbb{N}$)
The set of all positive integers (sometimes including zero).
- **Example**: {0,1,2,3,…}.
###### Integers ($\mathbb{Z}$)
The set of all positive and negative whole numbers, including zero.
	**Example**: {…,−3,−2,−1,0,1,2,3,…}.
###### Rational Numbers ($\mathbb{Q}$)
The set of all numbers that can be expressed as a fraction $\frac{p}{q}$​, where $p$ and $q$ are integers and $q \neq 0$.
    **Example**: ${\frac{1}{2}, -\frac{3}{4}, 2, \frac{22}{7}}$.
###### Real Numbers ($\mathbb{R}$)
The set of all rational and irrational numbers.
    **Example**: {0,1,π,2,−3.14}.
###### Complex Numbers ($\mathbb{C}$)
The set of all numbers of the form $a+bi$, where $a$ and $b$ are real numbers, and $i$ is the imaginary unit ($i^2 = -1$).
    **Example**: {1+2i,−3i,4}.
##### 2. Non-Numerical Sets
###### Sets of Functions
Function Spaces: The set of all continuous functions from a topological space $X$ to another space $Y$.
	**Example**: The set $C([0,1])$ of all continuous functions on the interval $[0,1]$.
###### Sets of Polynomials
Polynomial Rings: The set of all polynomials with coefficients from a given field.
	**Example**: The set of all polynomials with real coefficients, $\mathbb{R}[x]$.
###### Sets of Matrices
Matrix Spaces: The set of all $n \times m$ matrices over a field.
	**Example**: The set of all $2 \times 2$ matrices with real entries, denoted $\mathbb{R}^{2 \times 2}$.
###### Sets of Geometric Objects
Vector Spaces in Geometry: The set of all vectors in a vector space.
	**Example**: The set of all vectors in a 3-dimensional Euclidean space, $\mathbb{R}^3$.
###### Sets of Graphs
Graph Theory: The set of all graphs with a given property.
	**Example**: The set of all simple graphs with a fixed number of vertices.
###### Sets of Sequences
Sequence Spaces: The set of all sequences of elements from a given set.
	**Example**: The set of all infinite sequences of real numbers, $\ell^2$ (square-summable sequences).
###### Sets of Symbols or Characters
Formal Languages: The set of all strings of symbols from a given alphabet.
	**Example**: The set of all binary strings, $\{0,1\}^*$.
###### Topological Spaces
Open Sets: The set of all open sets in a topological space.
	**Example**: The collection of open intervals in the real line $\mathbb{R}$.
###### Algebraic Structures
Groups of Permutations: The set of all permutations of a given set.
	**Example**: The symmetric group $S_n$, the set of all permutations of $n$ elements.
##### Purpose of the Underlying Set
Serves as the theoretical "universe" encompassing all mathematical constructs.

- - - 
## Structured Set (i.e. Space) as the Subset of the Universal Superset
Is the result of the "first" application of constraint.
	Therefore, is the first relational structure, a level from which further relational structures (i.e. identities) can be derived from.
		With each subsequent "extending" or inclusion of additional structured, new relational structures (i.e. structured sets) are produced from the lower level relational structures.

When a set is endowed with a structure (i.e. applied constraints), it becomes a "structured set" or "space."
	"Structure" refers to additional operations, relations, and properties that are defined on a set to give it more meaning or to make it useful for certain purposes. 
		The structure itself is not a set but rather a framework of rules and operations applied to a set.

Structured sets are formed by taking a subset of the underlying set and adding a structure to it. 
	The additional structure defines how the elements of the underlying set interact.
		I.e. The combination of the underlying set and the additional structure. 
### The "Set" of the Structured Set
The Underlying Set is the "Set" of the Structured Set.
	This is the underlying set of elements that the structured set is built upon.

This Set is actually a subset of possible values, produced by constraining the parent set of values.
### The "Structure" of the Structured Set
The Structure is the Constraints.
	I.e. Structure on a set is the specification of added axioms, then [[Mapping#A Mapping Defines the Abstract Mathematical Spaces Structure Structure of a Abstract Mathematical Spaces Structured Set (i.e. Space) Structured Set|mappings]] that the [[Mapping#A Function as a Subset of Mappings ($1 1$, $m 1$)|functions]] and [[Mapping#An Operation as a Subset of Functions|operations]] must satisfy. 
		The structure defines how the elements of the set interact and behave according to certain rules.
#### 1. Axioms and Properties (Determine the Mappings) 
Rules or conditions that the Structure must satisfy (e.g., associativity, commutativity, distributivity).
	These are the conditions or rules that the operations must satisfy to ensure the set behaves in a particular way.
	
Axioms are fundamental truths or principles that are accepted without proof and serve as the starting point for defining a mathematical structure. 
	Properties are derived characteristics that follow from these axioms.

The axioms and properties of a structured set come first and define the nature of the mappings.
	Axioms establish the foundational rules and requirements that any mappings within the structure must satisfy.
		The structure of the set, including the domain, codomain, and range for each operation or relation, is defined by the axioms and properties of the structured set.
#### 2. [[Mapping|Mappings]] (Determine the Domain, Codomain, and Range)
The mappings ([[Mapping#A Function as a Subset of Relations ($1 1$, $m 1$)|functions]], [[Mapping#An Operation as a Subset of Functions|operations]]) applied to the Underlying Set establish the rules and behaviors (that are determined by the axioms) for how the elements of the set interact.  
	Thereby determining the structure of the domain, codomain, and range.
		I.e. Determine the specific roles and properties of the domain, codomain, and range within that structured set.
			These mappings specify the rules for how elements interact, thereby shaping the overall structure of the sets involved.
				Each Mapping (i.e. relation, function, operation) within a structured set has an associated domain, codomain, and range.
					The calculations we perform within a structured set help us discover and understand these values, which are inherent to the structure.

Mappings must adhere to the axioms and properties defined by the structure. 
	They are designed to satisfy the constraints and behaviors dictated by the axioms.
		Mappings (relations, functions, operations) are then defined in a way that satisfies the axioms. 
			The mappings are constructed to ensure that the structured set adheres to its defined properties.
#### 3. Domains, [[Axes and Dimensions#Codomain|Codomains]], and Ranges are the "Inherent Values" of a Structured Set
Domains, Codomains, and Ranges are possible values, that is, the [[Axes and Dimensions|axis or axes]] of a structured set.  
	That is, Domains, Codomains are the **sets of all possible values**, and can be represented "spatially" as "axes". 
		Basically a direction of sequenced values.

Domains, Codomains, and Ranges Are Structured by the Mappings which are themselves determined by the axioms.
	A Domain, Codomain, and Range is associated with each specific mapping of the structured set, determined by the axioms of the structure.
		These subsets therefore define the scope of inputs, potential outputs, and actual outputs of each of these mappings.
			A **variable** is a **selector** that picks a specific value from the set of all possible values represented by an axis.

The values and relationships within a structured set are inherent to the structure as defined by its axioms and properties, which are expressed by the mappings of that structure.
	Specific elements and their relationships that arise from the structure’s defining rules.
		They reflect the actual elements and interactions that exist within the structured set as dictated by the axioms and operations.

These Inherent Values (as Domains, Codomains and Ranges) already exist (independent of human calculation) upon the definition of the structure.
	The calculations we perform are methods to uncover and understand these inherent values and relationships.
##### [[Mapping#Domain as a Subset of the Underlying Set|Domain as a Subset of the Underlying Set]]
##### [[Mapping#Codomain as a Subset of Domain|Codomain as a Subset of Domain]]
##### [[Mapping#Range as a Subset of Codomain|Range as a Subset of Codomain]]

- - -
## Structuring/Equipping a Set (i.e. Space)
This refers to the general process of starting with an underlying set and defining operations, properties, and axioms to create a more complex mathematical object.
### Adding Structure to a Set
By defining operations ***on*** a set and imposing certain rules or axioms, we can impart structure to the set.
	"**Defining on a set**", means that the operation, function, or property is specified in such a way that it applies to the elements of the set and governs their interactions.
		This definition imparts structure to the set, transforming it into a structured set or space with specific mathematical properties.
			This term describes the process of defining operations and properties on an underlying set to form a structured set or space.
### The Relationship Between a Structured and the Underlying Set
#### Underlying Set is More Fundamental Than the Structured
An underlying set is more fundamental than the structure in the sense that it serves as the basic collection of elements upon which the structure is built.
	The structure is built on top of this set by defining specific operations and axioms, creating a more complex and rich mathematical object, and ensuring these operations satisfy certain properties and axioms.
### Sequence of Steps in Structuring a Set
##### 1. Start with an Underlying Set
Identify the basic set of elements that will form the foundation of the structured set.
- **Example**: The set of real numbers $\mathbb{R}$.
##### 2. Define Properties and Axioms
Specify the properties that the mappings must satisfy to ensure the set becomes a well-defined structured set.
> [!note] Examples
> - Associativity of addition: $(\mathbf{u} + \mathbf{v}) + \mathbf{w} = \mathbf{u} + (\mathbf{v} + \mathbf{w})$
> - Commutativity of addition: $\mathbf{u} + \mathbf{v} = \mathbf{v} + \mathbf{u}$
> - Identity element of addition: There exists a zero vector $\mathbf{0}$ such that $\mathbf{u} + \mathbf{0} = \mathbf{u}$
> - Inverse elements of addition: For each vector $\mathbf{u}$, there exists a vector $-\mathbf{u}$ such that $\mathbf{u} + (-\mathbf{u}) = $\mathbf{0}$
> - Distributivity: $a(\mathbf{u} + \mathbf{v}) = a\mathbf{u} + a\mathbf{v}$ and $(a + b)\mathbf{u} = a\mathbf{u} + b\mathbf{u}$
##### 3. Define the Mappings Such That the Axioms are Satisfied
Specify the operations that will be performed on the elements of the underlying set.
- **Example**:
    - Vector addition:
	    $$(x_1, y_1, z_1) + (x_2, y_2, z_2) = (x_1 + x_2, y_1 + y_2, z_1 + z_2)$$
    - Scalar multiplication: For a scalar $\LARGE a \in \mathbb{R}$
	    $$\LARGE a \cdot (x, y, z) = (a x, a y, a z)$$
##### 4. Form the Structured Set
- **Resulting Set**: Combine the underlying set with the defined axioms, mappings, and subsets () to form the structured set.
- **Example**: When the Underlying Set Real Numbers, $\mathbb{R}$, is defined along with additional structure  (i.e. axioms and relations) it then forms the Scalar Space, $R$.

- - -
## Types of Structured Sets (i.e. Spaces)
### 1. Algebraic Structured Sets
**Groups, Rings, Fields**: These terms come from the field of abstract algebra, where the focus is on algebraic operations and properties. They have been studied extensively and have well-established definitions and theories.

Groups, rings, and fields **are** technically types of structured sets or spaces, as they all consist of sets with additional operations and axioms. 
	The distinction often arises from the historical development and the specific contexts in which these terms are used.
		Using specific terms like "group," "ring," and "field" helps to precisely describe the nature of the structure and the specific operations and axioms involved. 
			This precision is crucial in mathematical discussions and writings to avoid ambiguity.

Therefore, despite technically being structured sets (spaces), they are not referred to as such. 
	While these can be viewed as "spaces" in a broad sense, they represent more narrowly defined structures compared to the wide variety of possible "spaces."
#### Groups
A set equipped with a single binary operation that satisfies the group axioms (closure, associativity, identity, and inverses).
#### Rings
A set equipped with two binary operations (addition and multiplication) that satisfy the ring axioms (additive commutativity, additive associativity, distributivity, etc.).

**Origin of the Term**
	The term "ring" comes from the German word "Zahlring," introduced by David Hilbert.
		 It refers to the cyclical nature of addition and multiplication operations within the set, similar to a ring structure where operations bring you back to elements within the set.
#### [[#The Sequential Generation of the Field of Real Numbers and the Vector Space|Fields]] (i.e. Algebraic Fields)
A set that is a commutative ring with the additional property that every non-zero element has a multiplicative inverse.

*See [[Fields#Abstract Mathematical Spaces Fields Algebraic Fields vs. Spatial Fields]] to compare Algebraic Fields and Spatial.*

**Origin of the Term**
The term "field" (German: "Körper") was introduced by Richard Dedekind. 
	In English, "field" was chosen to reflect the idea of a set with both additive and multiplicative operations that can be inverted (except for zero).
	
A field can be thought of as a "field" of numbers where every non-zero element has a multiplicative inverse, reflecting a rich, fertile structure allowing for extensive arithmetic operations.
##### Axioms of a Field
A field $F$ is a set with two operations (addition and multiplication) that satisfy the following axioms:
1. **Closure**: For all $\LARGE a, b \in F$, both $\LARGE a+b \text{ and } \cdot b$ are in $\LARGE F$.
2. **Associativity**: Both addition and multiplication are associative.
3. **Commutativity**: Both addition and multiplication are commutative.
4. **Identity Elements**: There exist elements $\LARGE 0 \in F$ and $\LARGE 1 \in F$ such that for all $\LARGE a \in F$, $\LARGE a + 0 = a$ and $\LARGE a \cdot 1 = a$.
5. **Additive Inverses**: For every $\LARGE a \in F$, there exists an element $\LARGE -a \in F$ such that $\LARGE a + (-a) = 0$.
6. **Multiplicative Inverses**: For every $\LARGE a \in F$ (except $0$), there exists an element $a^{-1} \in F$ such that $\LARGE a \cdot a^{-1} = 1$.
7. **Distributivity**: Multiplication is distributive over addition, i.e., $\LARGE a \cdot (b + c) = a \cdot b + a \cdot c$ for all $\LARGE a, b, c \in F$.
### 2. "Spaces" (Not Purely Algebraic)
The term "space" can refer to **any** set with additional structure, whether algebraic, topological, or geometric.
	Spaces often incorporate geometric or topological structures, such as distances, open sets, norms, and inner products, which are not typically considered in the purely algebraic structures of groups, rings, and fields.

The space refers to the set together with the defined structure (i.e. the operations and properties).

In mathematics, a **space** is a [[#Set Theory|set]] (sometimes known as a universe (i.e. a collection that contains all the entities one wishes to consider in a given situation) with a definition of relationships among the [[Abstract Mathematical Objects|Mathematical Objects]] of the set.
	Where "definition of relationships" refers to the "structure" of the space.
		And the "Mathematical Objects" refer to the elements of the underlying set within the space.
			Although the operations and functions of the space are also technically Mathematical Objects.

A space consists of selected mathematical objects that are treated as [[Points|points]].
and selected relationships between these points.
	The nature of the points can vary widely: for example, the points can represent numbers, functions on another space, or subspaces of another space. 
		It is the relationships (i.e. Morphisms) that define the nature of the space.

> [!NOTE] Examples of Spaces
>  ###### $R$ Space
> A 1D Vector Space consisting of all ordered triples of real numbers $(x, y, z)$.
> 	Each element in $R^3$ is a Vector, not a scalar. 
> 	Each vector element is composed of three scalars.
>  ###### $R^2$ Space
> A 2D Vector Space consisting of all ordered pairs of real numbers $(x, y)$.
> 	Each element in $R^2$ is a Vector, not a scalar. 
> 	Each vector element is composed of two scalars.
> ###### $R^3$ Space
> A 3D Vector Space consisting of all ordered triples of real numbers $(x, y, z)$.
> 	Each element in $R^3$ is a Vector, not a scalar. 
> 	Each vector element is composed of three scalars.
> ###### Metric Spaces
> A set with a distance function (metric) defined between elements.
	>**Example**: The set $\mathbb{R}$ with the usual distance function $d(x, y) = |x - y|$.
> ###### Topological Spaces
> Topological Spaces: A set with a topology, a collection of open sets satisfying certain axioms.
	> **Example**: The real line $\mathbb{R}$ with the standard topology.
> ###### Normed Spaces
> Normed Spaces: A vector space on which a norm is defined.
> 	**Example**: The set of all continuous functions on $[0,1]$ with the supremum norm, denoted $C([0,1])$.
> ###### Banach Spaces
> Banach Spaces: A complete normed vector space.
	> **Example**: The space of all continuous functions on $[0,1]$ with the supremum norm, denoted $C([0,1])$.
> ###### Hilbert Spaces
> Hilbert Spaces: A complete inner product space.
	> **Example**: The space of square-integrable functions, denoted $L^2([0,1])$.
> ###### Function Spaces
> Function Spaces: A set of functions from one space to another, often equipped with additional structure like pointwise operations or norms.
> 	**Example**: The set $C([0,1])$ of all continuous functions on the interval $[0,1]$.
> ###### Measure Spaces
Measure Spaces: A set equipped with a sigma-algebra and a measure.
> 	**Example**: The set $\mathbb{R}$ with the Lebesgue measure.
> ###### Manifolds
> Manifolds: A topological space that locally resembles Euclidean space.
> **Example**: The surface of a sphere, denoted $S^2$.
> ###### Fiber Bundles
> Fiber Bundles: A space that is locally a product space but globally may have a different topological structure.
> 	**Example**: The Möbius strip.
> ###### Sobolev Spaces
> Sobolev Spaces: Function spaces that can accommodate derivatives up to a certain order.
> 	**Example**: The set of functions on $[0,1]$ with square-integrable first derivatives, denoted $W^{1,2}([0,1])$.

- - -
## The Role of Composite Spaces in Inheritance and Extension

Yes, the fact that spaces are composite is a fundamental concept that enables both the inheritance of base-level functions and the extension of outputs to higher-level spaces. Let's break this down in detail:
### Composite Spaces

Composite spaces are mathematical structures that are built upon simpler, base-level spaces. These composite spaces allow for the combination and extension of functions, leading to more complex operations and mappings.

### Inheritance in Composite Spaces
##### Composite Functions Inherit and Thus Preserve Lower-Level Input Domains/Type
The input domain (or type) of the lower-level function is preserved in the composite function. 
	This means that the types of inputs the base function can accept remain the same when used within the composite function.

1. **Base-Level Functions**:
    - **Definition**: Base-level functions are simpler functions defined in lower-dimensional or more basic spaces.
    - **Example**: A scalar function $f: \mathbb{R} \rightarrow \mathbb{R}$ is a base-level function.

2. **Inheritance**:
    - **Preservation of Input Types**: In composite spaces, the input type (or domain) of the base-level function is preserved. This means the fundamental nature of the input space is maintained even when the function is extended to higher-dimensional spaces.
    - **Preservation of Properties**: The properties of the base-level function, such as continuity, differentiability, and linearity, are inherited by the higher-level function. This ensures that the composite function retains the fundamental characteristics of the base-level function.
	- **In Structured Sets**:
		- Inheritance in structured sets means that higher-level spaces retain the properties and elements of lower-level spaces.
	    - **Example**: A vector space Rn\mathbb{R}^nRn retains the field properties of R\mathbb{R}R.
	- **In Composite Functions**:
		- Composite functions retain the properties of the functions they are composed of.
	    - **Example**: If both component functions are continuous, the composite function is continuous.
### Extension in Composite Spaces
##### [[#A Transformation as a Subset of Composite Functions ($1 1$, $m 1$)|Transformations]] Extend Composite Functions and Preserve Higher-Level Output Codomain
Transformations take composite functions as their basis and enhance them, allowing these functions to operate in new and more complex contexts.

Transformations extend composite functions by modifying the output type to a higher-level or more complex codomain. 
	This means that while the function's input domain may be extended to more complex inputs, the output codomain is preserved and potentially expanded.
		When transformations extend composite functions, they ensure that the higher-level output codomain remains consistent. 
			This means that the type of outputs the function can produce is preserved, even as the function is extended to handle more complex inputs.

1. **Extension of Outputs**:
    - **Modification of Output Types**: In composite spaces, the output type (or codomain) of the base-level function is extended to higher-dimensional or more complex spaces. This means that while the input domain remains the same, the function's output is mapped to a higher-level space.
    - **Enhanced Functionality**: By extending the output, the function's applicability and complexity are increased. This allows the function to produce more detailed and sophisticated results.
    - **In Structured Sets**:
		- Extension in structured sets involves adding new dimensions or properties to create higher-level spaces.
	    - **Example**: A projective space Pn\mathbb{P}^nPn extends Rn\mathbb{R}^nRn by including points at infinity.
	- **In Transformations**:
		- Transformations extend functions by mapping them to higher-dimensional spaces or adding new properties.
	    - **Example**: A linear transformation extends a function from Rn\mathbb{R}^nRn to Rm\mathbb{R}^mRm.
### How [[Mapping#A Composite Function as a Subset of Functions|Composite Functions]] Enable [[Mapping#Input Type Preserved/Inherited from the Fundamental Functions (i.e. Base-Level Component Functions) Lower-Level Space|Inheritance]] and [[Mapping#Input Type Preserved (i.e. Determined) by Extensions Extension|Extension]]

1. **Composite Functions**:
    - Composite functions are formed by combining two or more base-level functions. This combination allows for the preservation of input types and the extension of output types.
    - **Example**: If $g: \mathbb{R}^p \rightarrow \mathbb{R}^n$ and $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$, the composite function $h(x) = f(g(x))$ inherits the input type from $g$ and extends the output type from $f$.

2. **Inheritance and Extension in Action**:
    - **Inheritance**: The composite function $h$ inherits the properties and input domain from the base-level function $g$. This means that $h$ will accept inputs from the same space as $g$ and will retain any properties $g$ possesses, such as continuity.
    - **Extension**: The composite function $h$ extends the output type of $f$, mapping the input from $\mathbb{R}^p$ through $\mathbb{R}^n$ to $\mathbb{R}^m$. This extension enables the function to produce more complex outputs, expanding its applicability.

### Example to Illustrate Inheritance and Extension

Consider the following example to illustrate the concepts of inheritance and extension in composite functions:

1. **Base-Level Function**:
    - Scalar function $f: \mathbb{R} \rightarrow \mathbb{R}$, defined as $f(x) = x^2$.

2. **Composite Function**:
    - Vector function $\mathbf{F}: \mathbb{R}^n \rightarrow \mathbb{R}^n$ that extends $f$ to operate on vectors, defined as $\mathbf{F}(\mathbf{x}) = (f(x_1), f(x_2), \ldots, f(x_n))$.

### Inheritance in the Example

- **Input Type Preservation**:
    - The input type (domain) of the scalar function $f$ is preserved in the vector function $\mathbf{F}$. Each component of the input vector $\mathbf{x}$ in $\mathbb{R}^n$ is individually processed by the scalar function $f$.
    - The properties of $f$, such as continuity and differentiability, are inherited by $\mathbf{F}$. This means that if $f$ is continuous and differentiable, so is $\mathbf{F}$.

### Extension in the Example

- **Output Type Extension**:
    - The output type (codomain) of the scalar function $f$ is extended from $\mathbb{R}$ to $\mathbb{R}^n$ in the vector function $\mathbf{F}$. Each component of the output vector is the result of applying $f$ to the corresponding component of the input vector.
    - This extension allows $\mathbf{F}$ to produce more complex outputs, enabling it to operate in higher-dimensional spaces.

- - -
## Generation of Composite Space: The Sequential Generation of the Field of Real Numbers and the Vector Space
*First, see the section on [[Mapping#A Composite Function as a Subset of Functions|A Composite Function as a Subset of Functions]] which describe the foundation of this sequence.*

A field as a mapping (whether a scalar field or a vector field) is a specific instance that must be defined explicitly. 
	There is no general field of values mapped to points unless specified by a particular function. 

When a Structured Set (for example, a vector space or a scalar space) is generated, the fields (scalar or vector fields) do not automatically exist. 
	Instead, these fields are defined based on functions that map points within those spaces to scalars or vectors.
### The Foundation: The Generation of the Real Number Field
#### 1. Real Numbers ($\mathbb{R}$) as the Underlying Set
The set of real numbers $\mathbb{R}$ is the collection of all rational and irrational numbers.
	This set itself has no additional structure (just the numbers).
##### Scalars are the Elements of the Real Number (Underlying) Set 
Aka Real Number Field Elements.
	Or just Field Elements for general fields.

In the context of the Real Number Field, $R$, Scalars are simply elements of the real number field.
	Every real number is a scalar in the context of vector spaces over $\mathbb{R}$.
		Scalars are elements of a field used to define operations such as scalar multiplication in vector spaces.

The properties of scalars (such as distributivity, associativity, and commutativity) are direct consequences of the field axioms that $\mathbb{R}$ satisfies.
	Scalars inherit the properties of the field $\mathbb{R}$ because they are elements of this field.
#### 2. Real Number Field ($\mathbb{R}$)
When we define addition and multiplication on $\mathbb{R}$ and show that these operations satisfy the field axioms (closure, associativity, commutativity, identity elements, inverses, and distributivity), we get the **Field of Real Numbers**, $\mathbb{R}$.
	This field $\mathbb{R}$ is an [[#1. Algebraic Structured Sets|Algebraic Structured Set]] where we can perform arithmetic operations.

The Real Number Field $\mathbb{R}$ is a set equipped with operations that satisfy field axioms.
	A field is a structured set equipped with two operations, addition and multiplication, that satisfy specific axioms (associativity, commutativity, distributivity, identity elements, and inverses).
##### The Structure of the Real Number Field ($\mathbb{R}$)
This Structure defines the rules (axioms, properties, and operations) that govern the elements of the real number field (i.e. Scalar) are defined by the structure of the real number field itself. 
###### Operations
**Addition**
A binary operation that combines two real numbers to produce another real number.
  - Notation: \( a + b \)
**Multiplication**
A binary operation that combines two real numbers to produce another real number.
  - Notation: \( a \cdot b \) or \( ab \)
###### Axioms
The real number field satisfies a specific set of axioms that define its structure and properties:
**Closure**:
- For all $a, b \in \mathbb{R}$:
  - $a + b \in \mathbb{R}$
  - $a \cdot b \in \mathbb{R}$
**Associativity**:
- For all $a, b, c \in \mathbb{R}$:
  - $(a + b) + c = a + (b + c)$
  - $(a \cdot b) \cdot c = a \cdot (b \cdot c)$
**Commutativity**:
- For all $a, b \in \mathbb{R}$:
  - $a + b = b + a$
  - $a \cdot b = b \cdot a$
**Identity Elements**:
- There exists an element $0 \in \mathbb{R}$ such that for all $a \in \mathbb{R}$:
  - $a + 0 = a$
- There exists an element $1 \in \mathbb{R}$ (where $1 \neq 0$) such that for all $a \in \mathbb{R}$:
  - $a \cdot 1 = a$
**Inverses**:
- For each $a \in \mathbb{R}$, there exists an element $-a \in \mathbb{R}$ such that:
  - $a + (-a) = 0$
- For each $a \in \mathbb{R}$ (where $a \neq 0$), there exists an element $a^{-1} \in \mathbb{R}$ such that:
  - $a \cdot a^{-1} = 1$
**Distributivity**:
- For all $a, b, c \in \mathbb{R}$:
  - $a \cdot (b + c) = (a \cdot b) + (a \cdot c)$
##### Scalar Functions
Scalar functions leverage the operations (while also satisfying the axioms) of the real number field (addition and multiplication) to map elements from a domain to scalar values in $\mathbb{R}$.
$$\LARGE f:R^n \to R$$
A **Scalar Function** is a mathematical function that maps points from an $n$-dimensional domain to a single real number (a scalar).
	They are generally used to to describe a relationship between variables where the output is a single scalar value.
		A more general term used across various mathematical disciplines. It emphasizes the mathematical relationship between the input and the output.
###### Scalar Functions are Defined by their Input Type and Output Type
Scalar functions are differentiated from other functions primarily by the type of their inputs and outputs.
###### Points of a Scalar Function
> [!note]
> Refers to elements of a set that serve as the domain of a function, without a spatial interpretation.
A "point" does not always need to have a spatial interpretation. 
>	A point can be an element of any set that serves as the domain of a function. 
> 
> **Abstract (Algebraic) Points in a Set** (For Scalar Functions)
> A point can be any element of a set that serves as the domain of a function.
> 	For a scalar function $: A \to \mathbb{R}$, where $A$ is a non-spatial set, points are elements of $A$.
> 		Example: Consider a set $S = \{a, b, c\}$.
> 			 A point in this set could be $a$, $b$, or $c$.
> 
> **Spatial Points in a Set** (For [[#Scalar Fields|Scalar Fields]])
> A spatial point is a specific location in a coordinate system that serves as the domain of a function.
> 	For a scalar function $f: \mathbb{R}^n \to \mathbb{R}$, where $\mathbb{R}^n$ is a spatial coordinate system, points are coordinates in $\mathbb{R}^n$.
> 		Example: Consider the 2-dimensional coordinate system $\mathbb{R}^2$.
> 			A point in this system could be $(x, y)$, where $x, y$ \in $\mathbb{R}$.

**Defining Characteristics**
1. **Domain**: The input can be elements from various sets, often points in a vector space like $\mathbb{R}^n$.
2. **Codomain**: The output is a single scalar value in the real number field $\mathbb{R}$.

Consider a scalar function $f$ defined as: $$\LARGE f(x, y) = x^2 + y^2$$
**Domain**: 
The domain of $f$ is $\mathbb{R}^2$, the set of all ordered pairs of real numbers $(x, y)$.
**Codomain**: 
The codomain of $f$ is $\mathbb{R}$, the set of real numbers.
**Operations**: 
The function uses addition and multiplication from the real number field:
    Squaring each component ($x^2$ and $y^2$).
    Adding the squared components ($x^2 + y^2$).
###### How Scalar Functions Utilize the Real Number Field
1. **Addition**: Scalar functions often involve addition of real numbers.
    - Example: In $f(x, y) = x^2 + y^2$, the addition operation combines the squared terms.
2. **Multiplication**: Scalar functions frequently use multiplication.
    - Example: In $f(x, y) = x^2 + y^2$, the squaring operation is a form of multiplication.
3. **Other Operations**: Scalar functions can also involve other operations that are defined in the field of real numbers, such as subtraction, division, and more complex functions like exponentiation or trigonometric functions.
###### What Mapping From One Domain to a Scalar Value Means
Scalar functions can have domains composed of various objects, not just real numbers.
	These domains can be multi-dimensional spaces, sets of vectors, matrices, or other mathematical objects.
		Scalar functions can map elements from complex domains (like vectors, matrices, or higher-dimensional points) to scalar values to simplify analysis or represent a specific quantity.

**Domains Composed of Vectors or Points in Space**
Often, the domain of a scalar function can be a set of vectors or points in a multi-dimensional space (e.g., $\mathbb{R}^n$). 
	*For example*: $f(x, y) = x^2 + y^2$
		Here, the domain is $\mathbb{R}^2$ (the set of all ordered pairs of real numbers), and $f$ maps each pair to a single real number (scalar) in $\mathbb{R}$.

This mapping is crucial in many fields of science and mathematics for simplifying complex structures or representing specific quantities like distance, temperature, or intensity.
**Examples**:
1. **Temperature Distribution**:
    - Domain: Points in a room (3D space, $\mathbb{R}^3$).
    - Scalar Function: $T(x, y, z)$ maps each point to a temperature value.
2. **Distance from Origin**:
    - Domain: Points in 2D space ($\mathbb{R}^2$).
    - Scalar Function: $d(x, y) = \sqrt{x^2 + y^2}$ maps each point to its distance from the origin.
3. **Intensity of a Field**:
    - Domain: Points in space where a field is defined (e.g., electric field, magnetic field).
    - Scalar Function: $I(x, y, z)$ might map each point to the intensity of the field at that point.
### [[#The Role of Composite Spaces in Inheritance and Extension|Building on the Foundation: Generating Vector Spaces *on Top of* the Real Number Field]]
#### "Defining a Space over a Field"
When we **define a Vector Space $V$ over the real number field** $\mathbb{R}$, we inherit and incorporate this field's underlying set and structure.
	Then the Vector Spaces adds additional elements to the Underlying Set, as well can extend the inherited structure, and/or add its own additional structure (i.e. operations and axioms) to form the vector space.

The Real Number Field doesn't just supply underlying set (Real Numbers) in a vector field, it also maintains its initial structure which the vector space inherits.
	Then the vector spaces defines **additional** structure on top of the existing structure of the Real Number Field.
		Remember that the Real Number Field ($\mathbb{R}$) is a structured set equipped with two operations, addition and multiplication, that satisfy specific axioms (associativity, commutativity, distributivity, identity elements, and inverses).
#### [[Mapping#Composite Functions are Defined by their Input and Output Types Through Inheritance and Extension|Preservation Through Inheritance and Extension of Function Output and Input Types]]

### Inheritance and Extension in the Context of Structured Spaces
**Higher Level Spaces Analogous to Composite Functions (Higher-Level Functions)**: Composite functions inherit properties (such as continuity and differentiability) from the functions they are composed of.

**Transformations of Additional/Extended Structure Analogous to Transformations as Subset of Composite Functions**: 
**Transformations and Extension of Structure**: Transformations extend the structure of lower-level spaces by mapping them into higher-level spaces, thus adding new dimensions or properties.
Transformations are indeed utilized in higher-level spaces as means of extending the structure and functionality of lower-level spaces.
#### Inheritance in Structured Sets (i.e. Spaces)
Inheritance in structured spaces refers to the process by which a higher-level space retains the fundamental properties, structure, and elements of a lower-level space.
	The underlying set and the elements of the lower-level space are preserved in the higher-level space, ensuring consistency and continuity in the properties and operations.
##### Properties Preserved in Inheritance
###### Set and Elements
The elements of the lower-level space are preserved in the higher-level space. 
	If the lower-level space is a subset of a field or another structured set, this subset is retained in the higher-level space.
		**Example**: The set of real numbers $\mathbb{R}$ in a vector space $\mathbb{R}^n$ is inherited when considering functions operating on $\mathbb{R}^n$.
###### Structural Properties
Properties such as continuity, differentiability, linearity, and algebraic operations (addition, multiplication) are preserved.
	**Example**: If a function $f: \mathbb{R} \rightarrow \mathbb{R}$ is continuous, then a vector function $\mathbf{F}: \mathbb{R}^n \rightarrow \mathbb{R}^n$ that applies $f$ component-wise inherits the continuity property.
#### Extension in Structured Sets (i.e. Spaces)
Extension in structured spaces refers to the process by which a higher-level space broadens or enhances the structure and functionality of a lower-level space. 
	This includes extending the types of operations, the dimensionality of the space, and the complexity of the elements within the space.
##### Properties Preserved in Extension
###### Set and Elements
The elements and structure of the lower-level space are extended to a higher-dimensional or more complex space.
	**Example**: Extending a scalar function $: \mathbb{R} \rightarrow \mathbb{R}$ to a vector function $\mathbf{F}: \mathbb{R}^n \rightarrow \mathbb{R}^m$ extends the scalar outputs to vector outputs.
###### Structural Properties
New properties or operations are added to the higher-level space, such as new dimensions, additional algebraic structures, or more complex relationships between elements.
	**Example**: A transformation that maps vectors in $\mathbb{R}^n$ to matrices in $\mathbb{R}^{n \times m}$ extends the structure by adding matrix operations and higher-dimensional interactions.
#### 1. The Underlying Set of the Vector Space
The Vector Space inherits the Underlying Set (i.e. Real Numbers) from the Real Number Field that it is defined on top of.
	But it also adds additional elements of its own.
##### The Inherited Elements
The scalars used in the Vector Space come from the Real Number Field $\mathbb{R}$.
	The Real Number Field provides the elements (i.e. scalars as Real Numbers) and the structure (i.e. axioms and operations of addition and multiplication) that are used in the vector space.

These scalar elements (i.e. Real Numbers) are still constrained by the initial Real Number Field Structure. 
	These scalars are used in scalar multiplication and define how vectors are scaled.
##### The Extended Elements
The vector space itself has its own set of elements called vectors.
	Vectors are constructed from the scalars of the field but are not simply elements of the field being inherited.
		The phrase "***not simply elements of the field inherited***" means that vectors in a vector space are constructed on this new layer (i.e. Vector Space).
			They are are composed of the inherited elements of the field to represent a new elements. 
				And are thus more complex structures than the individual elements (scalars) of the field they are built from. 
					This distinguishes them from the individual scalars that form their components.

Vectors consist of multiple components (scalars) arranged in an ordered tuple.
	This makes them inherently more complex than individual scalars.
		They are elements of the vector space, and they are constructed using the scalars from the field, but they are more complex than just single scalars.
		
Vectors represent new elements within the vector space, and they can have multiple dimensions depending on the number of scalars they contain.
	A vector in an $n$-dimensional space ($\mathbb{R}^n$) is an ordered $n$-tuple of scalars.
#### 2. The Structure of the Vector Space
##### The Inherited Structure
Vector spaces built over $\mathbb{R}$ inherit these fundamental properties and operations, ensuring that the structure and operations within the vector space maintain consistency and mathematical rigor.
	The real number field provides a robust foundation, ensuring that the vector spaces maintain certain algebraic properties and adhere to specific axioms.
	
When a space is defined on top of a field, it generally inherits the field's structure to the extent that the operations and axioms of the space require. 
	However, the space may not use all aspects of the field's structure directly. 
		Instead, it may focus on specific properties and operations provided by the field.
##### The Extended Structure
I.e. Extensions in the Vector Space.
###### Scalars in Scalar Multiplication
**Extended Definition:** Scalar functions in vector spaces maintain their scalar output while operating within higher-dimensional contexts.
	Scalars from the real number field ($\mathbb{R}$) are used to scale vectors in the vector space.
###### Scalar-Valued Functions on Vector Spaces:
###### Definition:
A scalar-valued function takes elements from a vector space and maps them to a scalar field.
###### Form
$f: V \to F$, where $V$ is a vector space and $F$ is a scalar field (e.g., $\mathbb{R}$ or $\mathbb{C}$).
###### Example
$f(\mathbf{v}) = \|\mathbf{v}\|$ where $f: \mathbb{R}^n \to \mathbb{R}$.
This function maps vectors in $\mathbb{R}^n$ to their magnitudes in $\mathbb{R}$.
###### Operations Involving Scalars
The addition and multiplication of scalars are used in the definitions of vector space operations.
###### Scalar Multiplication
For a scalar $a \in \mathbb{R}$ and a vector $\mathbf{v} \in V$, scalar multiplication is defined component-wise:
$$\LARGE  a \cdot (v_1, v_2, \ldots, v_n) = (a \cdot v_1, a \cdot v_2, \ldots, a \cdot v_n) $$
###### Vector Addition
Uses the inherited addition operation to add corresponding components of vectors:
$$\LARGE  (v_1, v_2, \ldots, v_n) + (w_1, w_2, \ldots, w_n) = (v_1 + w_1, v_2 + w_2, \ldots, v_n + w_n) $$
##### The Additional Structure
- **Vectors**: The primary elements of the vector space, which are ordered tuples of scalars (e.g., $\mathbb{R}^n$).
- **Vector Addition**: Defined for vectors in the space, combining them component-wise.
	- - **Additivity**: $T(\mathbf{u} + \mathbf{v}) = T(\mathbf{u}) + T(\mathbf{v})$
- **Scalar Multiplication**: Defined for vectors in the space, scaling each component of the vector by a scalar.
	- **Homogeneity (Scalar Multiplication)**: $T(c\mathbf{u}) = cT(\mathbf{u})$
- **Vector Space Axioms**:
  - **Closure**: For any vectors $\mathbf{u}, \mathbf{v} \in V$ and any scalar $a \in \mathbb{R}$, the results of $\mathbf{u} + \mathbf{v}$ and $a \cdot \mathbf{u}$ are also in $V$.
  - **Associativity of Vector Addition**: $\mathbf{u} + (\mathbf{v} + \mathbf{w}) = (\mathbf{u} + \mathbf{v}) + \mathbf{w}$.
  - **Commutativity of Vector Addition**: $\mathbf{u} + \mathbf{v} = \mathbf{v} + \mathbf{u}$.
  - **Existence of Additive Identity**: There exists a zero vector $\mathbf{0}$ such that $\mathbf{u} + \mathbf{0} = \mathbf{u}$.
  - **Existence of Additive Inverses**: For each vector $\mathbf{u}$, there exists an additive inverse $-\mathbf{u}$ such that $\mathbf{u} + (-\mathbf{u}) = \mathbf{0}$.
  - **Distributivity of Scalars over Vector Addition**: $a \cdot (\mathbf{u} + \mathbf{v}) = a \cdot \mathbf{u} + a \cdot \mathbf{v}$.
  - **Distributivity of Scalars over Scalar Addition**: $(a + b) \cdot \mathbf{u} = a \cdot \mathbf{u} + b \cdot \mathbf{u}$.
  - **Associativity of Scalar Multiplication**: $a \cdot (b \cdot \mathbf{u}) = (a \cdot b) \cdot \mathbf{u}$.
  - **Identity Element of Scalar Multiplication**: $1 \cdot \mathbf{u} = \mathbf{u}$ for any vector $\mathbf{u}$.
##### Vector Function
###### *Note: 
The term "point" and "vector" can often be used interchangeably in the context of vector spaces, as both represent an ordered tuple of numbers in a given space.*
	However, to maintain clarity and precision, especially in the context of vector spaces, it's better to explicitly use the term "vector" to avoid confusion with [[#Scalar Functions|Scalar Functions]].
$$\LARGE F:R^n \to R^m$$
A **Vector Function** is a mathematical function that maps a vector from an $n$-dimensional space (i.e. domain) to a vector in an $m$-dimensional vector space (i.e. codomain) - or possibly the same vector space.
	Vector functions are used broadly in mathematics to describe relationships between variables where the output is a vector.
###### Input
I.e. The Domain
	The domain of a vector function is typically an $n$-dimensional vector space, denoted as $\mathbb{R}^n$.
		This means the input to the function is a vector with $n$ components.
			Is Non-Spatial.
###### Output
I.e. The Codomain
	The codomain of a vector function is typically an $m$-dimensional vector space, denoted as $\mathbb{R}^m$.
		This means the output of the function is a vector with $m$ components.
			Is Non-Spatial.

A vector function $\mathbf{F}: \mathbb{R}^n \to \mathbb{R}^m$ can be expressed in terms of its component functions.
	Each component function maps from $\mathbb{R}^n$ to $\mathbb{R}$.
		For example, if $\mathbf{F}: \mathbb{R}^2 \to \mathbb{R}^3$, then: $\mathbf{F}(x, y) = \begin{pmatrix} f_1(x, y) \\ f_2(x, y) \\ f_3(x, y) \end{pmatrix}$ where $f_1, f_2,$ and $f_3$ are scalar-valued functions of two variables.

###### Example: 2D to 3D Vector Function
$$\LARGE \mathbf{F}(x, y) = \begin{pmatrix} x + y \\ x - y \\ xy \end{pmatrix}$$
Here, $\mathbf{F}$ maps a 2-dimensional vector $(x, y)$ to a 3-dimensional vector $(x + y, x - y, xy)$.
###### Example 3D to 3D Vector Function
Consider the vector function $\mathbf{F} : \mathbb{R}^3 \to \mathbb{R}^3$ defined by:
$$\LARGE \mathbf{F}(x, y, z) = \begin{pmatrix} -x \\ y^2 \\ z \end{pmatrix}$$
Here, $\mathbf{F}$ takes a 3-dimensional vector $(x, y, z)$ as input and maps it to a 3-dimensional vector.
###### Steps
1. **Input**: A 3-dimensional vector $(x, y, z) \in \mathbb{R}^3$.
2. **Output**: A 3-dimensional vector in $\mathbb{R}^3$.
###### Calculation
Let's compute $\mathbf{F}(x, y, z)$ for an example vector $(1, 2, 3)$:
$$\LARGE \mathbf{F}(1, 2, 3) = \begin{pmatrix} -1 \\ 2^2 \\ 3 \end{pmatrix}$$

$$\LARGE \mathbf{F}(1, 2, 3) = \begin{pmatrix} -1 \\ 4 \\ 3 \end{pmatrix}$$
###### Interpretation
- The function $\mathbf{F}(x, y, z) = \begin{pmatrix} -x \\ y^2 \\ z \end{pmatrix}$ takes a vector from $\mathbb{R}^3$ and produces another vector in $\mathbb{R}^3$.
- For the input vector $(1, 2, 3)$, the output is the vector $\begin{pmatrix} -1 \\ 4 \\ 3 \end{pmatrix}$.
###### Example: 3D to 1D Vector Function
Consider the vector function $\mathbf{F} : \mathbb{R}^3 \to \mathbb{R}$ defined by:
$$\LARGE  \mathbf{F}(x, y, z) = x + 2y + 3z$$

Here, $\mathbf{F}$ takes a 3-dimensional vector $(x, y, z)$ as input and maps it to a single real number (a scalar).
###### Steps
1. **Input**: A 3-dimensional vector $(x, y, z) \in \mathbb{R}^3$.
2. **Output**: A real number (scalar) in $\mathbb{R}$.
###### Calculation
Let's compute $\mathbf{F}(x, y, z)$ for an example vector $(1, 2, 3)$:
$$\LARGE \mathbf{F}(1, 2, 3) = 1 + 2 \cdot 2 + 3 \cdot 3$$
$$\LARGE \mathbf{F}(1, 2, 3) = 1 + 4 + 9$$
$$\LARGE \mathbf{F}(1, 2, 3) = 14$$
###### Interpretation
- The function $\mathbf{F}(x, y, z) = x + 2y + 3z$ takes a vector from $\mathbb{R}^3$ and produces a single real number in $\mathbb{R}$.
- For the input vector $(1, 2, 3)$, the output is the scalar $14$.

###### Vector Function Example 2
$$\mathbf{F}(t) = \begin{pmatrix} \cos(t) \\ \sin(t) \\ t \end{pmatrix}$$
**Domain**: 
The domain of a vector field is a space, often a vector space like $\mathbb{R}^n$. 
	For $\mathbf{F}(x, y, z)$, the domain is $\mathbb{R}^3$ (the 3-dimensional space).
**Codomain**: 
The codomain of a vector field is typically a set of vectors. 
	For $\mathbf{F}(x, y, z)$, the codomain is $\mathbb{R}^3$, which means each output is a vector with three components.
**Mapping**: The function maps each point in the domain to a vector in the codomain.

**Interpretation**: For each real number $t$, the function assigns a vector 
$$\begin{pmatrix} \cos(t) \\ \sin(t) \\ t \end{pmatrix} \space in \space \mathbb{R}^3$$
##### Vector Function as a Type of Vector Transformation (aka Linear Transformation)
###### Vector Transformation
A **vector transformation** is a general term for any function that maps vectors from one vector space to another. 
	This term encompasses both linear and non-linear transformations.

The term vector transformation is often used interchangeably with linear transformation in linear algebra, but it can also refer to more general mappings between vector spaces. 
	A vector transformation is any function that maps vectors from one vector space to another.
###### Example of Vector Transformation
A vector transformation can be either linear or non-linear. 
	For example, the linear transformation mentioned above is a vector transformation.
###### Linear Vector Function
A linear vector function, often called a linear transformation or a linear vector function, is a specific type of vector transformation between two vector spaces that preserves the operations of vector addition and scalar multiplication.
	Formally, a function $T: \mathbb{R}^n \to \mathbb{R}^m$ is a linear transformation if, for any vectors $\mathbf{u}, \mathbf{v} \in \mathbb{R}^n$ and any scalar $c \in \mathbb{R}$, the following properties hold:

- **Additivity**: 
  $T(\mathbf{u} + \mathbf{v}) = T(\mathbf{u}) + T(\mathbf{v})$
- **Homogeneity (Scalar Multiplication)**: 
  $T(c\mathbf{u}) = cT(\mathbf{u})$

So, all Linear Functions *are* Vector Transformations but not all Vector Transformations are Linear Vector Functions

Linear transformations can often be represented by matrices. 
	For example, if $T$ is a linear transformation from $\mathbb{R}^n$ to $\mathbb{R}^m$, there exists an $m \times n$ matrix $A$ such that for any vector $\mathbf{x} \in \mathbb{R}^n$:
$T(\mathbf{x}) = A \mathbf{x}$
###### Example of Linear Vector Function
Consider the linear transformation $T: \mathbb{R}^2 \to \mathbb{R}^2$ represented by the matrix:
$A = \begin{pmatrix} 2 & 0 \\ 0 & 3 \end{pmatrix}$
The function $T$ can be written as:
$T\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 2 & 0 \\ 0 & 3 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 2x \\ 3y \end{pmatrix}$
###### Non-Linear Vector Function
A non-linear vector function is a type Vector Transformation between two vector spaces that does not necessarily preserve vector addition and scalar multiplication. 
	Non-linear vector functions can involve more complex relationships between the input and output vectors.
###### Example of Non-Linear Vector Function
Consider the non-linear vector function $F: \mathbb{R}^2 \to \mathbb{R}^2$ defined by:
$F(x, y) = \begin{pmatrix} x^2 \\ \sin(y) \end{pmatrix}$
This function maps the vector $(x, y)$ to the vector $(x^2, \sin(y))$.
###### Key Differences
1. **Linear Vector Function (Linear Transformation)**:
   - Preserves vector addition and scalar multiplication.
   - Can be represented by a matrix.
   - Examples: Rotations, reflections, scaling transformations.

2. **Vector Transformation**:
   - General term that can refer to any mapping between vector spaces.
   - Can be either linear or non-linear.
   - Linear transformations are a subset of vector transformations.

3. **Non-Linear Vector Function**:
   - Does not necessarily preserve vector addition and scalar multiplication.
   - Involves more complex mappings that cannot be represented by a simple matrix multiplication.
   - Examples: Polynomial transformations, trigonometric transformations.
#### How Do These Structures Vary Among Different $n$ of Vector Spaces ($\mathbb{R}^1, \mathbb{R}^2, \mathbb{R}^3$)?
##### $\mathbb{R}^1$ - One-Dimensional Metric Space:
- **Elements**: Single real numbers (e.g., $x$).
- **Vector Addition**: $x + y$
- **Scalar Multiplication**: $a \cdot x$
- **Structure**: Inherits and applies all vector space axioms in the simplest form.
##### $\mathbb{R}^2$ - Two-Dimensional Vector Space:
- **Elements**: Ordered pairs of real numbers (e.g., $(x, y)$).
- **Vector Addition**: $(x_1, y_1) + (x_2, y_2) = (x_1 + x_2, y_1 + y_2)$
- **Scalar Multiplication**: $a \cdot (x, y) = (a \cdot x, a \cdot y)$
- **Structure**: Extends the structure of $\mathbb{R}^1$ to two dimensions, applying vector space axioms to pairs of real numbers.
##### $\mathbb{R}^3$ - Three-Dimensional Vector Space:
- **Elements**: Ordered triples of real numbers (e.g., $(x, y, z)$).
- **Vector Addition**: $(x_1, y_1, z_1) + (x_2, y_2, z_2) = (x_1 + x_2, y_1 + y_2, z_1 + z_2)$
- **Scalar Multiplication**: $a \cdot (x, y, z) = (a \cdot x, a \cdot y, a \cdot z)$
- **Structure**: Extends the structure of $\mathbb{R}^2$ to three dimensions, applying vector space axioms to triples of real numbers.
##### $\mathbb{R}^n$ - $n$-Dimensional Vector Space:
- **Elements**: Ordered $n$-tuples of real numbers (e.g., $(x_1, x_2, \ldots, x_n)$).
- **Vector Addition**: $(x_1, x_2, \ldots, x_n) + (y_1, y_2, \ldots, y_n) = (x_1 + y_1, x_2 + y_2, \ldots, x_n + y_n)$
- **Scalar Multiplication**: $a \cdot (x_1, x_2, \ldots, x_n) = (a \cdot x_1, a \cdot x_2, \ldots, a \cdot x_n)$
- **Structure**: Generalizes the structure of lower-dimensional spaces to $n$ dimensions, applying vector space axioms to $n$-tuples of real numbers.
#### Vector Spaces and $\mathbb{R}^n$
When we refer to $\mathbb{R}^1, \mathbb{R}^2, \mathbb{R}^3$, etc., we are indeed talking about vector spaces, where the "vector" in the name is often implied but not always explicitly mentioned.
	These are the most common examples of vector spaces built upon the real number field.
###### Vectors in $\mathbb{R}$
Represents the set of all real numbers, which can be seen as a one-dimensional metric space.
	The elements of are simply real numbers.
###### Vectors in $\mathbb{R}^2$
Represents the set of all ordered pairs of real numbers, forming a two-dimensional vector space.
	The elements are ordered pairs of real numbers.
	Example: $\mathbf{v} = (x, y)$ where $x,y∈Rx, y \in \mathbb{R}$.
###### Vectors in $\mathbb{R}^3$
Represents the set of all ordered triples of real numbers, forming a three-dimensional vector space.
	The elements are ordered triples of real numbers.
	Example: $\mathbf{w} = (x, y, z)$ where $x, y, z \in \mathbb{R}$.
###### Vectors in $\mathbb{R}^n$
More generally, $\mathbb{R}^n$ represents the set of all ordered $n$-tuples of real numbers, forming an $n$-dimensional vector space.
	The elements are ordered $n$-tuples of real numbers.
	Example: $\mathbf{u} = (x_1, x_2, \ldots, x_n)u=(x1​,x2​,…,xn​) \text{ where } x_i \in \mathbb{R}$ for all $i$.
#### Other Structures Built Upon the Real Number Field
While $\mathbb{R}^n$ spaces are vector spaces, there are other mathematical structures built upon the real number field that are not vector spaces.

- - -
## "Space" vs. "Spatial"
A vector space becomes "spatial" when it is used to represent geometric or physical space.

All vector spaces can be considered "abstract" or "algebraic" when viewed purely in terms of their algebraic properties (addition and scalar multiplication).
### Scalar/Metric Space $\mathbb{R}^1$ as Vector Space $\mathbb{R}^1$ (i.e. simply $\mathbb{R}$)
#### Abstract Vector Space
As a vector space $V$ over a field $F$ (commonly the field of real numbers $\mathbb{R}$ or complex numbers $\mathbb{C}$) is an abstract mathematical structure consisting of all real numbers with standard addition and scalar multiplication.
#### Spatial Interpretation:
When $\mathbb{R}$ is used to represent physical quantities along a single dimension (such as positions along a line), it can be considered spatial.
	Example: The real number line can be used to represent positions along a one-dimensional space. In this context, $\mathbb{R}$ is spatial.
### Vector Space $\mathbb{R}^2$ and $\mathbb{R}^3$
They are not inherently "non-spatial"; rather, they can be interpreted in either an abstract algebraic sense or a concrete spatial sense, depending on the context.
#### Naturally Spatial
$\mathbb{R}^2$ and $\mathbb{R}^3$ are naturally interpreted as spatial because they correspond to 2D and 3D physical spaces, respectively.
##### $\mathbb{R}^2$
Represents points in a plane.
	Each vector $(x, y)$ can be visualized as a point in a 2D Cartesian coordinate system.
##### $\mathbb{R}^3$
Represents points in 3D space.
	Each vector $(x, y, z)$ can be visualized as a point in a 3D Cartesian coordinate system.

- - - 
## Spatial Field as a Subset of Transformations
A spatial field in general implies a continuous (i.e. real number) distribution of some output over a spatial domain. 
	Whether the output is a scalar, a vector, or something more complex, the key idea is that there is a specific value or set of values associated with every point in the spatial domain. 
	
A spatial field can be broadly defined as a function that maps points in a spatial domain (such as $\mathbb{R}^2$, $\mathbb{R}^3$, or higher dimensions) to some output in a codomain. 
	The output can be a scalar, a vector, a tensor, or even more complex structures.
$$\LARGE f:R^n \to S$$
Where $s$ is the set of possible values .
	(e.g., $\mathbb{R}$ for scalar fields, $\mathbb{R}^m$ for vector fields).
		
A **field** in a spatial context is an abstract mathematical concept used to describe how certain quantities vary over a given spatial domain. 
	A field is a function that assigns a value to every point in a spatial domain, where the domain is a subset of $\mathbb{R}^n$.
		This value can be a scalar, vector, or more complex mathematical entity, depending on the type of field.
#### Defining Characteristics
**Spatial Domain**
The domain is a spatial region, meaning each input to the field corresponds to a specific location in space.
	The domain of a field is a spatial region, typically represented as a subset of $\mathbb{R}^n$.
		 This means that each point in the domain corresponds to a specific location in $n$-dimensional space.
**Range (i.e. Value Assignment)**
The field maps/assigns a value (scalar, vector, etc.) to each point in the spatial domain.
	The range of a field can vary depending on the type of field:
		For **scalar fields**, the range is $\mathbb{R}$ (real numbers).
		For **vector fields**, the range is typically $\mathbb{R}^m$ (vectors in $m$-dimensional space).
		For more complex fields, the range could be other mathematical structures, such as tensors.
**Continuity**
The field provides a continuous distribution of these outputs over the spatial domain, meaning each point in the domain has a corresponding value or set of values.
	In many applications, fields are continuous functions, meaning that small changes in the input (spatial coordinates) result in small changes in the output value.
##### Continuous Distribution (in Spatial Fields)
Refers to a function that assigns values smoothly across the entire domain without abrupt changes or gaps. 
	Meaning that the values assigned by the field vary smoothly and gradually across the entire domain, ensuring that the field is well-defined at every point, and small changes in position lead to small changes in the field’s value.
		Therefore, the output value (whether scalar, vector, tensor, etc.) at any given point in the domain varies smoothly and gradually as you move from one point to another within the domain.
###### Mathematical Continuity
A function $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$ is continuous if, for any point $\mathbf{p}$ in the domain and any arbitrarily small positive number $\epsilon$, there exists a corresponding small positive number $\delta$ such that if the distance between any point $\mathbf{q}$ and $\mathbf{p} is less than $\delta$, then the distance between $f(\mathbf{q})$ and $f(\mathbf{p})$ is less than $\epsilon$.
	In simpler terms, small changes in the input lead to small changes in the output.
###### Implications for Spatial Fields:
- **Smooth Variation**: The values assigned by the field change smoothly as you move through the domain. There are no sudden jumps or discontinuities.
- **No Gaps**: The field is defined at every point in the domain, with no missing values or undefined regions.
### Scalar Fields
A **Scalar Field** is a Scalar Function that maps ***every* points from spatial domain** (which can be viewed as a vector space) to scalar values from an algebraic field (e.g., $\mathbb{R}$).
	A mapping from points in a space (like $\mathbb{R}^3$) to scalar values in $\mathbb{R}$.
		A scalar field is not a single scalar value but a continuous distribution of scalar values across a domain.

The **key difference** between a Scalar Function and a Scalar Field is that the domain of a Scalar Field is typically **a spatial domain**, meaning each input point corresponds to a location in space.
	Used primarily in the context of vector calculus and physical sciences. It emphasizes the spatial distribution of scalar values.

**Domain**: Spatial
Typically a vector space like $\mathbb{R}^n$.
	The domain of a scalar field is spatial, often a vector space like $\mathbb{R}^n$.
		 For $f(x, y)$, the domain is $\mathbb{R}^2$ (the 2-dimensional plane).
**Codomain**: Non-Spatial
The codomain of a scalar field is typically the set of real numbers, $\mathbb{R}$.
**Range**:
The set of real numbers $\mathbb{R}$.
**Mapping**:
The function maps each point in the domain to a scalar value in the codomain.

###### Scalar Field Example
$$T(x, y, z) = x^2 + y^2$$
**Domain**: 
$\mathbb{R}^2$
	The function $f(x, y) = x^2 + y^2$ takes points $(x, y)$ from the 2-dimensional plane $\mathbb{R}^2$.
**Codomain**: The function outputs scalar values in $\mathbb{R}$. For any point $(x, y)$, $f(x, y)$ is a real number.
**Range**: $\mathbb{R}$
**Mapping**: For each point $(x, y)$ in $\mathbb{R}^2$, the function $f$ assigns the value $x^2 + y^2$. This value is a scalar (a real number).

**Interpretation**: For each point $(x, y, z)$ in a 3D space, the field assigns a value, which could represent a temperature distribution.
#### Scalar Field Representation
You can visualize a scalar field as a surface or a heat map where each point has a specific value. 
	For example, a temperature distribution over a surface can be represented as a scalar field where each point on the surface has a corresponding temperature value.
### Vector Fields
###### *Note: 
The term "point" and "vector" can often be used interchangeably in the context of vector spaces, as both represent an ordered tuple of numbers in a given space.*

A **Vector Field** is a Vector Function that maps ***every* point in a spatial domain**, $R^2$ or $R^3$, to a vector in a codomain.
	A vector field always implies an array (or more precisely, a continuous distribution) of vectors, not just a single vector.
		It describes how a vector quantity (like velocity, force, or electric field) varies over space.
			It is a continuous mapping/distribution from a domain (e.g., $\mathbb{R}^2$ or $\mathbb{R}^3$) to a codomain of vectors.

Vector Fields map points in a space to vectors, where the components of these vectors are scalar values from an algebraic field (e.g., $\mathbb{R}$).
	Vector Functions are used to describe vector values distributed over space.
		Specifically used to describe vector quantities that vary over a spatial region, often in physics and engineering.
			Vector fields are used primarily in physics and vector calculus to describe spatially varying vector quantities.

**Domain**: Spatial
Typically a vector space like $\mathbb{R}^n$.
	The domain of a scalar field is a spatial, often a vector space like $\mathbb{R}^n$.
		 For $f(x, y)$, the domain is $\mathbb{R}^2$ (the 2-dimensional plane).
**Codomain**: Non-Spatial
A vector space, often $\mathbb{R}^m$, where $m$ is the dimension of the vectors.
	Where $m$ is the dimension of the vectors assigned to each point in the domain.
**Range**: 
The set of all possible vectors that the function can assign, which is a subset of the codomain.
**Mapping**: 
The function assigns a vector to each point in the domain.
#### Vector Field Representation
A vector field can be visualized as an array of vectors, one at each point in the domain.
	This array is continuous, meaning that as you move smoothly through the domain, the vectors change smoothly as well.
		 This continuous distribution of vectors describes how the vector quantity varies over space.

A Vector Field is [[Derivatives#Continuities Continuity|Continuous]] if its components are continuous.

A vector field in $R^2$ can be represented in either of two equivalent ways. 
##### 1. A Vector with Components that are Two-Variable Functions
$$\LARGE \vec{F}(x,y) = \begin{pmatrix} P(x,y) \\ Q(x,y) \end{pmatrix}$$
##### 2. Standard Unit Vectors
$$\LARGE \vec{F}(x,y) = P(x,y)\hat{i} + Q(x,y)\hat{j}$$
###### Example Finding a Vector Mapped to a Given Point
The following is a Vector Field in $R^2$.
$$\LARGE \vec{F}(x,y) = (2y^2 + x - 4)\hat{i} + \cos(x)\hat{j}$$
Solution via substituting point values $(0,-1)$ for $x$ and $y$:
$$\LARGE \vec{F}(0,-1) = (2(-1)^2+0-4)\hat{i} + \cos(0)\hat{j}$$
$$\LARGE = 2\hat{i} + \hat{j}$$
#### Fields vs. Graphs
When we refer to scalar fields or vector fields in mathematics, we are talking about functions that map points in a space to values (scalars or vectors).

The "graph" of a function typically represents the set of all points $(x, f(x))$ for scalar functions or ($\mathbf{x}, \mathbf{F(x)}$) for vector functions.
##### Fields can be Represented by Graphs
The "graph" of a scalar field is a surface in higher-dimensional space, while the graph of a vector field is a collection of vectors in the domain space.

The graph of a scalar field $f: \mathbb{R}^2 \to \mathbb{R}$ can be visualized as a surface in $\mathbb{R}^3$, where each point $(x, y, z)$ represents $(x, y, f(x, y))$.

The graph of a vector field can be visualized as a collection of vectors (arrows) at each point in the domain, showing the direction and magnitude of the field.
##### Graph of Vector Field
We can now represent a vector field in terms of its components of functions or unit vectors, but representing it visually by sketching it is more complex because the domain of a vector field is in $R^2$, as is the range. 
	Therefore the “graph” of a vector field in $R^2$ lives in four-dimensional space.
###### Why It Lives in Four-Dimensional Space
The statement about the vector field "living in four-dimensional space" refers to the combined space required to represent both the input and output dimensions:
- **Input Dimensions (Domain)**: The points $(x, y)$ span a 2-dimensional space ($\mathbb{R}^2$).
- **Output Dimensions (Range)**: The vectors $\mathbf{F}(x, y) = (P(x, y), Q(x, y))$ also lie in a 2-dimensional space ($\mathbb{R}^2$).
To fully capture the relationship between the input (points in $\mathbb{R}^2$) and output (vectors in $\mathbb{R}^2$), you need a four-dimensional space: 
	Two dimensions for the domain and two dimensions for the range.
- - -












## The Frameworks for Abstract Mathematical Space
Describing and Comparing Abstract Mathematical Space
### Set Theory as a Foundation for Abstract Environments
##### Structural Frameworks
**Abstract Mathematical Spaces** are **sets equipped with [[#Additional Structure (not equivalent to Mathematical Structure)|additional structure]]**, which defines operations, relations, or other **properties** that **define** **how** **[[#Underlying Set (i.e. Base Set)|elements]]** of the **set** (which the Abstract Space also contains within it) **interact** and **relate** to **each** **other**.
#### Set Theory
Set theory provides the **foundational framework** for **describing and defining abstract mathematical environments/spaces**. 
	It does so by formalizing the concept of a collection of objects, which can include anything from numbers and geometric points to functions and other more complex structures. 
###### The [[#Underlying Set (i.e. Base Set)|Underlying Set]]: Basic Elements - Sets: 
- **Definition of Sets**: In set theory, a set is defined simply as a collection of distinct objects, which can be anything—mathematical, conceptual, or even physical. These objects are called the elements or members of the set.
- **Examples**: Sets can include the set of natural numbers {1,2,3,...}{1,2,3,...}, the set of points in a geometric space, or the set of solutions to a particular equation.
###### The [[#Additional Structure (not equivalent to Mathematical Structure)|Additional Structure Set]]: Structure and Operations on Sets:
- **Operations**: Set theory introduces several fundamental operations that can be performed with sets, such as union, intersection, set difference, and complement. These operations allow for the construction of new sets from existing ones, providing a way to build more complex structures and relationships.
- **Subsets and Power Sets**: The concept of subsets (sets wholly contained within another set) and power sets (the set of all possible subsets of a set) are central in exploring the internal structure of sets and their potential complexity.
- **Function and Mappings**:
	- **Functions as Set Relations**: Functions are defined in set theory as a special kind of relation (itself a set of ordered pairs) that assigns exactly one element of one set to each element of another set. Functions are crucial for describing transformations and interactions between elements of sets and thus are integral to defining abstract mathematical operations within environments.
	- **Injective, Surjective, Bijective**: These concepts describe how functions relate sets to each other, crucial for understanding structure preservation in more complex mathematical contexts.
- **Foundational Axioms**:
	- **Zermelo-Fraenkel Axioms with the Axiom of Choice (ZFC)**: The axiomatic system most commonly used today in set theory. These axioms formalize the behavior of sets under various operations and conditions, providing a rigorous foundation for most of modern mathematics.
	- **Axioms**: Include axioms that describe how sets are formed, how they can be compared, and what constitutes an element of a set. These rules form the basis for virtually all mathematical analysis performed in more complex abstract environments.
**Defining Abstract Mathematical Environments**:
- **Role in Other Disciplines**: Set theory's concepts are used to define the spaces and structures in other areas of mathematics. For example, in topology, a topological space is defined as a set of points along with a set of "open" subsets that satisfy certain properties. In algebra, structures like groups, rings, and fields are defined using sets equipped with one or more operations.
**Universality**: 
The general applicability of set theory makes it a universal language for discussing and defining abstract mathematical environments across all fields of mathematics and related disciplines.
### Category Theory
Category theory extends beyond traditional set theory by focusing on the relationships between structures rather than just the structures themselves. 

Category theory provides a [[#Higher-Level Set Set (i.e. Category/Class of Structures/Universal)|high-level framework]] (i.e. the set containing the [[#Structured Set|Structured Set]]) for describing and comparing Abstract Mathematical Environments as well as mathematical structures by emphasizing the relationships between abstract mathematical objects and the structure-preserving transformations (functors) that can exist between different categories.
	I.e. By **abstracting the essence of mathematical objects and focusing on how they interact.**
		This makes it a cornerstone of modern mathematical theory, enabling a deeper understanding of structures and their interrelations across various branches of mathematics and beyond.

A category is defined by a **set of objects** and **morphisms** (arrows) between those objects that satisfy certain compositional properties. 
![[Pasted image 20240421082147.png|400]]
##### Morphisms 
- **Primary Focus**: In category theory, the primary focus is on the relationships (morphisms) between objects. This perspective is particularly useful for comparing how different structures behave and interact, rather than just comparing the structures (objects) themselves.
- **Composition of Morphisms**: Morphisms can be composed, meaning if there is a morphism from object A to object B, and another from B to C, then there must also be a morphism from A to C. This composition must be associative, and for each object, there must be an identity morphism that acts as a neutral element in morphism composition.
##### Functors and Natural Transformations:
- **[[Mapping|Mappings]]**:
	- These tools in category theory allow for the mapping of objects and morphisms in one category to objects and morphisms in another, preserving their structural relationships. 
	- Functors are mappings between categories that preserve the structure defined by objects and morphisms.
	- A functor maps objects to objects and morphisms to morphisms, respecting the compositional structure (i.e., it preserves identities and compositions). 
	- Functors are essential for relating different categories and for transferring properties and structures between them.
	- Functors can compare and relate different abstract environments, while natural transformations provide a way to compare functors.
- **Natural Transformations**:
	- These provide a way to transform one functor into another while respecting the structure of the categories involved. 
	- Natural transformations are central in expressing how one categorical construction can be morphed into another smoothly.
##### Higher-Level Structures (Not Higher-Level Sets):
- **Limits and Colimits**:
	- Category theory defines concepts like limits and colimits, which generalize constructions such as products, coproducts, intersections, and unions. These are crucial for discussing completeness and the existence of certain universal properties in categories.
- **Adjunctions**: 
	- An adjunction is a pair of functors that go between two categories, which are universal with respect to a certain property. Adjunctions help in defining free objects and forgetful functors and are pivotal in linking different mathematical contexts.
###### Versatility in Application:
Category theory is not restricted to any specific type of mathematical structure. It can describe sets, spaces, groups, rings, vector spaces, and more, as long as these can be conceptualized as objects with morphisms between them. This versatility makes it a powerful tool for describing a wide range of abstract environments.

The abstract environment in category theory is the entire category itself, which abstractly encapsulates the objects and their interactions.
